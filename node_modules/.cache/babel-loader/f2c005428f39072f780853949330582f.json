{"ast":null,"code":"//     wink-pos-tagger\n//     English Part-of-speech (POS) tagger\n//\n//     Copyright (C) 2017-19  GRAYPE Systems Private Limited\n//\n//     This file is part of “wink-pos-tagger”.\n//\n//     Permission is hereby granted, free of charge, to any person obtaining a\n//     copy of this software and associated documentation files (the \"Software\"),\n//     to deal in the Software without restriction, including without limitation\n//     the rights to use, copy, modify, merge, publish, distribute, sublicense,\n//     and/or sell copies of the Software, and to permit persons to whom the\n//     Software is furnished to do so, subject to the following conditions:\n//\n//     The above copyright notice and this permission notice shall be included\n//     in all copies or substantial portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n//     OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n//     FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n//     LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n//     FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n//\nvar helpers = require('wink-helpers');\n\nvar winkLexicon = require('wink-lexicon/src/lexicon.js');\n\nvar unigramPOSTagger = require('./unigram-tagger.js');\n\nvar applyContextRules = require('./rules-engine.js');\n\nvar wl = require('wink-lemmatizer');\n\nvar lemmatizeVBX = wl.lemmatizeVerb;\nvar lemmatizeNNX = wl.lemmatizeNoun;\nvar lemmatizeJJX = wl.lemmatizeAdjective; // Load tokenizer, instanciate and get tokenize method; use default config.\n\nvar tokenize = require('wink-tokenizer')().tokenize; // Extract string normalization function from `wink-helpers`.\n\n\nvar normalize = helpers.string.normalize;\nvar lemmaExceptions = Object.create(null);\nlemmaExceptions.ai = 'be';\nlemmaExceptions.ca = 'can';\nlemmaExceptions.sha = 'shall';\nlemmaExceptions['\\'ll'] = lemmaExceptions.wo = 'will';\nlemmaExceptions['\\'ve'] = 'have';\nlemmaExceptions['\\'m'] = 'am';\nlemmaExceptions['\\'re'] = 'be';\nlemmaExceptions['n\\'t'] = 'not';\nlemmaExceptions['\\'d'] = 'would'; // Needed for simple NNP transformation rule.\n\nconst capA = 'A';\nconst capZ = 'Z'; // Required in raw tokens tagging\n\nconst rgxNumber = /^\\d+\\/\\d+|\\d(?:[\\.\\,\\-\\/]?\\d)*(?:\\.\\d+)?$/;\nconst rgxPunctuation = /^[\\’\\'\\‘\\’\\`\\“\\”\\\"\\[\\]\\(\\)\\{\\}\\…\\,\\.\\!\\;\\?\\-\\:]+$/; // Used in tagging years.\n\nconst year = Object.create(null);\nyear['1990s'] = 'CD';\nyear['1980s'] = 'CD';\nyear['1970s'] = 'CD';\nyear['1960s'] = 'CD';\nyear['1950s'] = 'CD';\nyear['1940s'] = 'CD';\nyear['1930s'] = 'CD';\nyear['1910s'] = 'CD';\nyear['mid-1990s'] = 'CD';\nyear['mid-1980s'] = 'CD';\nyear['mid-1970s'] = 'CD';\nyear['mid-1960s'] = 'CD';\nyear['mid-1950s'] = 'CD';\nyear['mid-1940s'] = 'CD';\nyear['mid-1930s'] = 'CD';\nyear['mid-1920s'] = 'CD';\nyear['mid-1910s'] = 'CD'; // ### posTagger\n\n/**\n *\n * Creates an instance of {@link Tagger}.\n *\n * @return {Tagger} object conatining set of API methods for pos-tagging.\n * @example\n * // Load wink tokenizer.\n * var tagger = require( 'wink-pos-tagger' );\n * // Create your instance of wink tokenizer.\n * var myTagger = posTagger();\n*/\n\nvar posTagger = function () {\n  /**\n  * @classdesc Tagger class\n  * @class Tagger\n  * @hideconstructor\n  */\n  var methods = Object.create(null); // ### updateLexicon\n\n  /**\n   *\n   * Updates the internal lexicon using the input `lexicon`. If a word/pos pair\n   * is found in the internal lexicon then it's value is updated with the new pos;\n   * otherwise it added.\n   *\n   * @method Tagger#updateLexicon\n   * @param {object} lexicon containing **`word/pos`** pairs to be added to or\n   * replaced in the existing lexicon. The `pos` should be an array containing\n   * pos tags, with the first one as the most frequently used POS. The `word` is\n   * normalized before updating the internal lexicon.\n   * @return {undefined} Nothing!\n   * @throws {Error} if `lexicon` is not a valid JS object.\n   * @example\n   * myTagger.updateLexicon( { Obama: [ 'NNP' ] } );\n  */\n\n  var updateLexicon = function (lexicon) {\n    if (!helpers.validate.isObject(lexicon)) {\n      throw Error('wink-pos-tagger/updateLexicon: lexicon must be an object, instead found: ' + JSON.stringify(lexicon));\n    } // Update winkLexicon but with **normalized** key.\n\n\n    for (var key in lexicon) winkLexicon[normalize(key)] = lexicon[key]; // eslint-disable-line guard-for-in\n\n  }; // updateLexicon()\n  // ### defineConfig\n\n  /**\n   *\n   * This API has no effect. It has been maintained for compatibility purpose.\n   * The `wink-tokenizer` will now always add **lemma** and **normal** forms.\n   * Note, lemmas are added only for **nouns** (excluding proper noun), **verbs** and\n   * **adjectives**.\n   *\n   * @method Tagger#defineConfig\n   * @return {object} always as `{ lemma: true, normal: true }`.\n   * @example\n   * // There will not be any effect:\n   * var myTagger.defineConfig( { lemma: false } );\n   * // -> { lemma: true, normal: true }\n  */\n\n\n  var defineConfig = function () {\n    // Return a copy of configuration object.\n    return JSON.parse(JSON.stringify({\n      lemma: true,\n      normal: true\n    }));\n  }; // defineConfig()\n  // ### lemmatize\n\n  /**\n   *\n   * Performs lemmatization; also applies NNP transformation rules for captitalized\n   * nouns and adjectives and CD rule for years.\n   *\n   * @method Tagger#lemmatize\n   * @param {object[]} tokens to be lemmatized.\n   * @return {object[]} lemmatized tokens.\n   * @private\n  */\n\n\n  var lemmatize = function (tokens) {\n    var t, v0, w;\n    var lemma;\n    var tpos;\n\n    for (let i = 0, imax = tokens.length; i < imax; i += 1) {\n      t = tokens[i];\n      w = t.normal;\n      v0 = t.value[0];\n      tpos = year[w];\n      if (tpos) t.pos = 'CD'; // First handle exceptions arising out of contractions.\n\n      lemma = lemmaExceptions[w];\n\n      if (lemma) {\n        t.lemma = lemma;\n      } else {\n        // Otherwise use lemmatizer.\n        switch (t.pos[0]) {\n          case 'J':\n            if (v0 >= capA && v0 <= capZ) {\n              t.lemma = w;\n              t.pos = 'NNP';\n            } else {\n              t.lemma = t.pos.length > 2 ? lemmatizeJJX(w) : w;\n            }\n\n            break;\n\n          case 'V':\n            t.lemma = t.pos.length > 2 ? t.normal === '\\'s' ? 'be' : lemmatizeVBX(w) : w;\n            break;\n\n          case 'N':\n            if (v0 >= capA && v0 <= capZ) {\n              t.lemma = w;\n              t.pos = 'NNP';\n            } else {\n              // No lemmatization of NNPs please!\n              t.lemma = t.pos !== 'NNP' && t.pos.length > 2 ? lemmatizeNNX(w) : w;\n            }\n\n            break;\n\n          case 'M':\n            t.lemma = lemmatizeVBX(w);\n            break;\n\n          default: // Do nothing!\n\n        } // swtich\n\n      } // if\n\n    }\n\n    return tokens;\n  }; // lemmatize()\n  // ### tag\n\n  /**\n   *\n   * Tags the input **`tokens`** with their **pos**. It has another alias – **`tagTokens()`**.\n   *\n   * *In order to pos tag a sentence directly, use\n   * [`tagSentence`](http://winkjs.org/wink-pos-tagger/Tagger.html#tagSentence)\n   * API instead.*\n   *\n   * @method Tagger#tag\n   * @param {object[]} tokens to be pos tagged. They are array of objects and\n   * must follow the [**`wink-tokenizer`**](http://winkjs.org/wink-tokenizer/)\n   * standard.\n   * @return {object[]} pos tagged `tokens`.\n   * @example\n   * // Get `tokenizer` method from the instance of `wink-tokenizer`.\n   * var tokenize = require( 'wink-tokenizer' )().tokenize;\n   * // Tag the tokenized sentence.\n   * myTagger.tag( tokenize( 'I ate the entire pizza as I was feeling hungry.' ) );\n   * // -> [ { value: 'I', tag: 'word', normal: 'i', pos: 'PRP' },\n   * //      { value: 'ate', tag: 'word', normal: 'ate', pos: 'VBD', lemma: 'eat' },\n   * //      { value: 'the', tag: 'word', normal: 'the', pos: 'DT' },\n   * //      { value: 'entire', tag: 'word', normal: 'entire', pos: 'JJ', lemma: 'entire' },\n   * //      { value: 'pizza', tag: 'word', normal: 'pizza', pos: 'NN', lemma: 'pizza' },\n   * //      { value: 'as', tag: 'word', normal: 'as', pos: 'IN' },\n   * //      { value: 'I', tag: 'word', normal: 'i', pos: 'PRP' },\n   * //      { value: 'was', tag: 'word', normal: 'was', pos: 'VBD', lemma: 'be' },\n   * //      { value: 'feeling', tag: 'word', normal: 'feeling', pos: 'VBG', lemma: 'feel' },\n   * //      { value: 'hungry', tag: 'word', normal: 'hungry', pos: 'JJ', lemma: 'hungry' },\n   * //      { value: '.', tag: 'punctuation', normal: '.', pos: '.' } ]\n  */\n\n\n  var tag = function (tokens) {\n    // Array of \"array each possible pos\" for each token.\n    var poses = []; // Temp token & word.\n\n    var t;\n\n    for (let i = 0, imax = tokens.length; i < imax; i += 1) {\n      t = tokens[i]; // Normalize, if configuration demands it!\n\n      t.normal = normalize(t.value);\n      poses.push(unigramPOSTagger(t, winkLexicon));\n    }\n\n    applyContextRules(tokens, poses); // Lemmatize, if configuration demands...\n\n    lemmatize(tokens);\n    return tokens;\n  }; // tagTokens();\n  // ### tagRawTokens\n\n  /**\n   *\n   * Tags the **`raw tokens`** with their **pos**. Note, it only categorizes each\n   * token in to one of the following 3-categories (a) word, or (b) punctuation,\n   * or (c) number.\n   *\n   * *In order to pos tag a sentence directly, use\n   * [`tagSentence`](http://winkjs.org/wink-pos-tagger/Tagger.html#tagSentence)\n   * API instead.*\n   *\n   * @method Tagger#tagRawTokens\n   * @param {string[]} rawTokens to be pos tagged. They are simple array of string.\n   * @return {object[]} pos tagged `tokens`.\n   * @example\n   * var rawTokens = [ 'I', 'ate', 'the', 'entire', 'pizza', 'as', 'I', 'was', 'feeling', 'hungry', '.' ];\n   * // Tag the raw tokens.\n   * myTagger.tagRawTokens( rawTokens );\n   * // -> [ { value: 'I', tag: 'word', normal: 'i', pos: 'PRP' },\n   * //      { value: 'ate', tag: 'word', normal: 'ate', pos: 'VBD', lemma: 'eat' },\n   * //      { value: 'the', tag: 'word', normal: 'the', pos: 'DT' },\n   * //      { value: 'entire', tag: 'word', normal: 'entire', pos: 'JJ', lemma: 'entire' },\n   * //      { value: 'pizza', tag: 'word', normal: 'pizza', pos: 'NN', lemma: 'pizza' },\n   * //      { value: 'as', tag: 'word', normal: 'as', pos: 'IN' },\n   * //      { value: 'I', tag: 'word', normal: 'i', pos: 'PRP' },\n   * //      { value: 'was', tag: 'word', normal: 'was', pos: 'VBD', lemma: 'be' },\n   * //      { value: 'feeling', tag: 'word', normal: 'feeling', pos: 'VBG', lemma: 'feel' },\n   * //      { value: 'hungry', tag: 'word', normal: 'hungry', pos: 'JJ', lemma: 'hungry' },\n   * //      { value: '.', tag: 'punctuation', normal: '.', pos: '.' } ]\n  */\n\n\n  var tagRawTokens = function (rawTokens) {\n    // Will contain tokens transformed into wink format tokens\n    var wt = [];\n    var t;\n\n    for (var i = 0, imax = rawTokens.length; i < imax; i += 1) {\n      t = rawTokens[i];\n\n      if (rgxNumber.test(t)) {\n        wt.push({\n          value: t,\n          tag: 'number'\n        });\n      } else if (rgxPunctuation.test(t)) {\n        wt.push({\n          value: t,\n          tag: 'punctuation'\n        });\n      } else wt.push({\n        value: t,\n        tag: 'word'\n      });\n    }\n\n    return tag(wt);\n  }; // tagRawTokens()\n  // ### tagSentence\n\n  /**\n   *\n   * Tags the input `sentence` with their **pos**.\n   *\n   * @method Tagger#tagSentence\n   * @param {string} sentence to be pos tagged.\n   * @return {object[]} pos tagged `tokens.`\n   * @throws {Error} if `sentence` is not a valid string.\n   * @example\n   * myTagger.tagSentence( 'A bear just crossed the road.' );\n   * // -> [ { value: 'A', tag: 'word', normal: 'a', pos: 'DT' },\n   * //      { value: 'bear', tag: 'word', normal: 'bear', pos: 'NN', lemma: 'bear' },\n   * //      { value: 'just', tag: 'word', normal: 'just', pos: 'RB' },\n   * //      { value: 'crossed', tag: 'word', normal: 'crossed', pos: 'VBD', lemma: 'cross' },\n   * //      { value: 'the', tag: 'word', normal: 'the', pos: 'DT' },\n   * //      { value: 'road', tag: 'word', normal: 'road', pos: 'NN', lemma: 'road' },\n   * //      { value: '.', tag: 'punctuation', normal: '.', pos: '.' } ]\n   * //\n   * //\n   * myTagger.tagSentence( 'I will bear all the expenses.' );\n   * // -> [ { value: 'I', tag: 'word', normal: 'i', pos: 'PRP' },\n   * //      { value: 'will', tag: 'word', normal: 'will', pos: 'MD', lemma: 'will' },\n   * //      { value: 'bear', tag: 'word', normal: 'bear', pos: 'VB', lemma: 'bear' },\n   * //      { value: 'all', tag: 'word', normal: 'all', pos: 'PDT' },\n   * //      { value: 'the', tag: 'word', normal: 'the', pos: 'DT' },\n   * //      { value: 'expenses', tag: 'word', normal: 'expenses', pos: 'NNS', lemma: 'expense' },\n   * //      { value: '.', tag: 'punctuation', normal: '.', pos: '.' } ]\n  */\n\n\n  var tagSentence = function (sentence) {\n    if (typeof sentence !== 'string') {\n      throw Error('wink-pos-tagger: input sentence must be a string, instead found: ' + typeof sentence);\n    }\n\n    return tag(tokenize(sentence));\n  }; // tagSentence()\n\n\n  methods.updateLexicon = updateLexicon;\n  methods.tag = tag;\n  methods.tagTokens = tag;\n  methods.tagRawTokens = tagRawTokens;\n  methods.tagSentence = tagSentence;\n  methods.defineConfig = defineConfig;\n  return methods;\n}; // posTagger()\n\n\nmodule.exports = posTagger;","map":{"version":3,"names":["helpers","require","winkLexicon","unigramPOSTagger","applyContextRules","wl","lemmatizeVBX","lemmatizeVerb","lemmatizeNNX","lemmatizeNoun","lemmatizeJJX","lemmatizeAdjective","tokenize","normalize","string","lemmaExceptions","Object","create","ai","ca","sha","wo","capA","capZ","rgxNumber","rgxPunctuation","year","posTagger","methods","updateLexicon","lexicon","validate","isObject","Error","JSON","stringify","key","defineConfig","parse","lemma","normal","lemmatize","tokens","t","v0","w","tpos","i","imax","length","value","pos","tag","poses","push","tagRawTokens","rawTokens","wt","test","tagSentence","sentence","tagTokens","module","exports"],"sources":["D:/Getty-Search-Media-Results/node_modules/wink-pos-tagger/src/wink-pos-tagger.js"],"sourcesContent":["//     wink-pos-tagger\n//     English Part-of-speech (POS) tagger\n//\n//     Copyright (C) 2017-19  GRAYPE Systems Private Limited\n//\n//     This file is part of “wink-pos-tagger”.\n//\n//     Permission is hereby granted, free of charge, to any person obtaining a\n//     copy of this software and associated documentation files (the \"Software\"),\n//     to deal in the Software without restriction, including without limitation\n//     the rights to use, copy, modify, merge, publish, distribute, sublicense,\n//     and/or sell copies of the Software, and to permit persons to whom the\n//     Software is furnished to do so, subject to the following conditions:\n//\n//     The above copyright notice and this permission notice shall be included\n//     in all copies or substantial portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n//     OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n//     FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n//     LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n//     FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\nvar helpers = require( 'wink-helpers' );\nvar winkLexicon = require( 'wink-lexicon/src/lexicon.js' );\nvar unigramPOSTagger = require( './unigram-tagger.js' );\nvar applyContextRules = require( './rules-engine.js' );\nvar wl = require( 'wink-lemmatizer' );\nvar lemmatizeVBX = wl.lemmatizeVerb;\nvar lemmatizeNNX = wl.lemmatizeNoun;\nvar lemmatizeJJX = wl.lemmatizeAdjective;\n// Load tokenizer, instanciate and get tokenize method; use default config.\nvar tokenize = require( 'wink-tokenizer' )().tokenize;\n// Extract string normalization function from `wink-helpers`.\nvar normalize = helpers.string.normalize;\n\nvar lemmaExceptions = Object.create( null );\nlemmaExceptions.ai = 'be';\nlemmaExceptions.ca = 'can';\nlemmaExceptions.sha = 'shall';\nlemmaExceptions[ '\\'ll' ] = lemmaExceptions.wo = 'will';\nlemmaExceptions[ '\\'ve' ] = 'have';\nlemmaExceptions[ '\\'m' ] = 'am';\nlemmaExceptions[ '\\'re' ] = 'be';\nlemmaExceptions[ 'n\\'t' ] = 'not';\nlemmaExceptions[ '\\'d' ] = 'would';\n// Needed for simple NNP transformation rule.\nconst capA = 'A';\nconst capZ = 'Z';\n// Required in raw tokens tagging\nconst rgxNumber = /^\\d+\\/\\d+|\\d(?:[\\.\\,\\-\\/]?\\d)*(?:\\.\\d+)?$/;\nconst rgxPunctuation = /^[\\’\\'\\‘\\’\\`\\“\\”\\\"\\[\\]\\(\\)\\{\\}\\…\\,\\.\\!\\;\\?\\-\\:]+$/;\n// Used in tagging years.\nconst year = Object.create( null );\nyear[ '1990s' ] = 'CD';\nyear[ '1980s' ] = 'CD';\nyear[ '1970s' ] = 'CD';\nyear[ '1960s' ] = 'CD';\nyear[ '1950s' ] = 'CD';\nyear[ '1940s' ] = 'CD';\nyear[ '1930s' ] = 'CD';\nyear[ '1910s' ] = 'CD';\nyear[ 'mid-1990s' ] = 'CD';\nyear[ 'mid-1980s' ] = 'CD';\nyear[ 'mid-1970s' ] = 'CD';\nyear[ 'mid-1960s' ] = 'CD';\nyear[ 'mid-1950s' ] = 'CD';\nyear[ 'mid-1940s' ] = 'CD';\nyear[ 'mid-1930s' ] = 'CD';\nyear[ 'mid-1920s' ] = 'CD';\nyear[ 'mid-1910s' ] = 'CD';\n\n// ### posTagger\n/**\n *\n * Creates an instance of {@link Tagger}.\n *\n * @return {Tagger} object conatining set of API methods for pos-tagging.\n * @example\n * // Load wink tokenizer.\n * var tagger = require( 'wink-pos-tagger' );\n * // Create your instance of wink tokenizer.\n * var myTagger = posTagger();\n*/\nvar posTagger = function ( ) {\n\n  /**\n  * @classdesc Tagger class\n  * @class Tagger\n  * @hideconstructor\n  */\n  var methods = Object.create( null );\n\n  // ### updateLexicon\n  /**\n   *\n   * Updates the internal lexicon using the input `lexicon`. If a word/pos pair\n   * is found in the internal lexicon then it's value is updated with the new pos;\n   * otherwise it added.\n   *\n   * @method Tagger#updateLexicon\n   * @param {object} lexicon containing **`word/pos`** pairs to be added to or\n   * replaced in the existing lexicon. The `pos` should be an array containing\n   * pos tags, with the first one as the most frequently used POS. The `word` is\n   * normalized before updating the internal lexicon.\n   * @return {undefined} Nothing!\n   * @throws {Error} if `lexicon` is not a valid JS object.\n   * @example\n   * myTagger.updateLexicon( { Obama: [ 'NNP' ] } );\n  */\n  var updateLexicon = function ( lexicon ) {\n    if ( !helpers.validate.isObject( lexicon ) ) {\n      throw Error( 'wink-pos-tagger/updateLexicon: lexicon must be an object, instead found: ' + JSON.stringify( lexicon ) );\n    }\n    // Update winkLexicon but with **normalized** key.\n    for ( var key in lexicon ) winkLexicon[ normalize( key ) ] = lexicon[ key ]; // eslint-disable-line guard-for-in\n  }; // updateLexicon()\n\n  // ### defineConfig\n  /**\n   *\n   * This API has no effect. It has been maintained for compatibility purpose.\n   * The `wink-tokenizer` will now always add **lemma** and **normal** forms.\n   * Note, lemmas are added only for **nouns** (excluding proper noun), **verbs** and\n   * **adjectives**.\n   *\n   * @method Tagger#defineConfig\n   * @return {object} always as `{ lemma: true, normal: true }`.\n   * @example\n   * // There will not be any effect:\n   * var myTagger.defineConfig( { lemma: false } );\n   * // -> { lemma: true, normal: true }\n  */\n  var defineConfig = function ( ) {\n    // Return a copy of configuration object.\n    return ( JSON.parse( JSON.stringify( { lemma: true, normal: true } ) ) );\n  }; // defineConfig()\n\n  // ### lemmatize\n  /**\n   *\n   * Performs lemmatization; also applies NNP transformation rules for captitalized\n   * nouns and adjectives and CD rule for years.\n   *\n   * @method Tagger#lemmatize\n   * @param {object[]} tokens to be lemmatized.\n   * @return {object[]} lemmatized tokens.\n   * @private\n  */\n  var lemmatize = function ( tokens ) {\n    var t, v0, w;\n    var lemma;\n    var tpos;\n    for ( let i = 0, imax = tokens.length; i < imax; i += 1 ) {\n      t = tokens[ i ];\n      w = t.normal;\n      v0 = t.value[ 0 ];\n      tpos = year[ w ];\n      if ( tpos ) t.pos = 'CD';\n      // First handle exceptions arising out of contractions.\n      lemma = lemmaExceptions[ w ];\n      if ( lemma ) {\n        t.lemma = lemma;\n      } else {\n        // Otherwise use lemmatizer.\n        switch ( t.pos[ 0 ] ) {\n          case 'J':\n            if ( ( v0 >= capA ) && ( v0 <= capZ ) ) {\n              t.lemma = w;\n              t.pos = 'NNP';\n            } else {\n              t.lemma = ( t.pos.length > 2 ) ? lemmatizeJJX( w ) : w;\n            }\n            break;\n          case 'V':\n            t.lemma = ( t.pos.length > 2 ) ?\n                        ( ( t.normal === '\\'s') ? 'be' : lemmatizeVBX( w ) ) :\n                        w;\n            break;\n          case 'N':\n            if ( ( v0 >= capA ) && ( v0 <= capZ ) ) {\n              t.lemma = w;\n              t.pos = 'NNP';\n            } else {\n              // No lemmatization of NNPs please!\n              t.lemma = ( t.pos !== 'NNP' && t.pos.length > 2 ) ? lemmatizeNNX( w ) : w;\n            }\n            break;\n          case 'M':\n            t.lemma = lemmatizeVBX( w );\n            break;\n          default:\n            // Do nothing!\n        } // swtich\n      } // if\n    }\n\n    return tokens;\n  }; // lemmatize()\n\n  // ### tag\n  /**\n   *\n   * Tags the input **`tokens`** with their **pos**. It has another alias – **`tagTokens()`**.\n   *\n   * *In order to pos tag a sentence directly, use\n   * [`tagSentence`](http://winkjs.org/wink-pos-tagger/Tagger.html#tagSentence)\n   * API instead.*\n   *\n   * @method Tagger#tag\n   * @param {object[]} tokens to be pos tagged. They are array of objects and\n   * must follow the [**`wink-tokenizer`**](http://winkjs.org/wink-tokenizer/)\n   * standard.\n   * @return {object[]} pos tagged `tokens`.\n   * @example\n   * // Get `tokenizer` method from the instance of `wink-tokenizer`.\n   * var tokenize = require( 'wink-tokenizer' )().tokenize;\n   * // Tag the tokenized sentence.\n   * myTagger.tag( tokenize( 'I ate the entire pizza as I was feeling hungry.' ) );\n   * // -> [ { value: 'I', tag: 'word', normal: 'i', pos: 'PRP' },\n   * //      { value: 'ate', tag: 'word', normal: 'ate', pos: 'VBD', lemma: 'eat' },\n   * //      { value: 'the', tag: 'word', normal: 'the', pos: 'DT' },\n   * //      { value: 'entire', tag: 'word', normal: 'entire', pos: 'JJ', lemma: 'entire' },\n   * //      { value: 'pizza', tag: 'word', normal: 'pizza', pos: 'NN', lemma: 'pizza' },\n   * //      { value: 'as', tag: 'word', normal: 'as', pos: 'IN' },\n   * //      { value: 'I', tag: 'word', normal: 'i', pos: 'PRP' },\n   * //      { value: 'was', tag: 'word', normal: 'was', pos: 'VBD', lemma: 'be' },\n   * //      { value: 'feeling', tag: 'word', normal: 'feeling', pos: 'VBG', lemma: 'feel' },\n   * //      { value: 'hungry', tag: 'word', normal: 'hungry', pos: 'JJ', lemma: 'hungry' },\n   * //      { value: '.', tag: 'punctuation', normal: '.', pos: '.' } ]\n  */\n  var tag = function ( tokens ) {\n    // Array of \"array each possible pos\" for each token.\n    var poses = [];\n    // Temp token & word.\n    var t;\n    for ( let i = 0, imax = tokens.length; i < imax; i += 1 ) {\n      t = tokens[ i ];\n      // Normalize, if configuration demands it!\n      t.normal = normalize( t.value );\n      poses.push( unigramPOSTagger( t, winkLexicon ) );\n    }\n    applyContextRules( tokens, poses );\n    // Lemmatize, if configuration demands...\n    lemmatize( tokens );\n    return tokens;\n  }; // tagTokens();\n\n  // ### tagRawTokens\n  /**\n   *\n   * Tags the **`raw tokens`** with their **pos**. Note, it only categorizes each\n   * token in to one of the following 3-categories (a) word, or (b) punctuation,\n   * or (c) number.\n   *\n   * *In order to pos tag a sentence directly, use\n   * [`tagSentence`](http://winkjs.org/wink-pos-tagger/Tagger.html#tagSentence)\n   * API instead.*\n   *\n   * @method Tagger#tagRawTokens\n   * @param {string[]} rawTokens to be pos tagged. They are simple array of string.\n   * @return {object[]} pos tagged `tokens`.\n   * @example\n   * var rawTokens = [ 'I', 'ate', 'the', 'entire', 'pizza', 'as', 'I', 'was', 'feeling', 'hungry', '.' ];\n   * // Tag the raw tokens.\n   * myTagger.tagRawTokens( rawTokens );\n   * // -> [ { value: 'I', tag: 'word', normal: 'i', pos: 'PRP' },\n   * //      { value: 'ate', tag: 'word', normal: 'ate', pos: 'VBD', lemma: 'eat' },\n   * //      { value: 'the', tag: 'word', normal: 'the', pos: 'DT' },\n   * //      { value: 'entire', tag: 'word', normal: 'entire', pos: 'JJ', lemma: 'entire' },\n   * //      { value: 'pizza', tag: 'word', normal: 'pizza', pos: 'NN', lemma: 'pizza' },\n   * //      { value: 'as', tag: 'word', normal: 'as', pos: 'IN' },\n   * //      { value: 'I', tag: 'word', normal: 'i', pos: 'PRP' },\n   * //      { value: 'was', tag: 'word', normal: 'was', pos: 'VBD', lemma: 'be' },\n   * //      { value: 'feeling', tag: 'word', normal: 'feeling', pos: 'VBG', lemma: 'feel' },\n   * //      { value: 'hungry', tag: 'word', normal: 'hungry', pos: 'JJ', lemma: 'hungry' },\n   * //      { value: '.', tag: 'punctuation', normal: '.', pos: '.' } ]\n  */\n  var tagRawTokens = function ( rawTokens ) {\n    // Will contain tokens transformed into wink format tokens\n    var wt = [];\n    var t;\n    for ( var i = 0, imax = rawTokens.length; i < imax; i += 1 ) {\n      t = rawTokens[ i ];\n      if ( rgxNumber.test( t ) ) {\n        wt.push( { value: t, tag: 'number' } );\n      } else if ( rgxPunctuation.test( t ) ) {\n        wt.push( { value: t, tag: 'punctuation' } );\n      } else wt.push( { value: t, tag: 'word' } );\n    }\n\n    return tag( wt );\n  }; // tagRawTokens()\n\n  // ### tagSentence\n  /**\n   *\n   * Tags the input `sentence` with their **pos**.\n   *\n   * @method Tagger#tagSentence\n   * @param {string} sentence to be pos tagged.\n   * @return {object[]} pos tagged `tokens.`\n   * @throws {Error} if `sentence` is not a valid string.\n   * @example\n   * myTagger.tagSentence( 'A bear just crossed the road.' );\n   * // -> [ { value: 'A', tag: 'word', normal: 'a', pos: 'DT' },\n   * //      { value: 'bear', tag: 'word', normal: 'bear', pos: 'NN', lemma: 'bear' },\n   * //      { value: 'just', tag: 'word', normal: 'just', pos: 'RB' },\n   * //      { value: 'crossed', tag: 'word', normal: 'crossed', pos: 'VBD', lemma: 'cross' },\n   * //      { value: 'the', tag: 'word', normal: 'the', pos: 'DT' },\n   * //      { value: 'road', tag: 'word', normal: 'road', pos: 'NN', lemma: 'road' },\n   * //      { value: '.', tag: 'punctuation', normal: '.', pos: '.' } ]\n   * //\n   * //\n   * myTagger.tagSentence( 'I will bear all the expenses.' );\n   * // -> [ { value: 'I', tag: 'word', normal: 'i', pos: 'PRP' },\n   * //      { value: 'will', tag: 'word', normal: 'will', pos: 'MD', lemma: 'will' },\n   * //      { value: 'bear', tag: 'word', normal: 'bear', pos: 'VB', lemma: 'bear' },\n   * //      { value: 'all', tag: 'word', normal: 'all', pos: 'PDT' },\n   * //      { value: 'the', tag: 'word', normal: 'the', pos: 'DT' },\n   * //      { value: 'expenses', tag: 'word', normal: 'expenses', pos: 'NNS', lemma: 'expense' },\n   * //      { value: '.', tag: 'punctuation', normal: '.', pos: '.' } ]\n  */\n  var tagSentence = function ( sentence ) {\n    if ( typeof sentence !== 'string' ) {\n      throw Error( 'wink-pos-tagger: input sentence must be a string, instead found: ' + typeof sentence );\n    }\n    return tag( tokenize( sentence ) );\n  }; // tagSentence()\n\n  methods.updateLexicon = updateLexicon;\n  methods.tag = tag;\n  methods.tagTokens = tag;\n  methods.tagRawTokens = tagRawTokens;\n  methods.tagSentence = tagSentence;\n  methods.defineConfig = defineConfig;\n\n  return methods;\n}; // posTagger()\n\nmodule.exports = posTagger;\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA,IAAIA,OAAO,GAAGC,OAAO,CAAE,cAAF,CAArB;;AACA,IAAIC,WAAW,GAAGD,OAAO,CAAE,6BAAF,CAAzB;;AACA,IAAIE,gBAAgB,GAAGF,OAAO,CAAE,qBAAF,CAA9B;;AACA,IAAIG,iBAAiB,GAAGH,OAAO,CAAE,mBAAF,CAA/B;;AACA,IAAII,EAAE,GAAGJ,OAAO,CAAE,iBAAF,CAAhB;;AACA,IAAIK,YAAY,GAAGD,EAAE,CAACE,aAAtB;AACA,IAAIC,YAAY,GAAGH,EAAE,CAACI,aAAtB;AACA,IAAIC,YAAY,GAAGL,EAAE,CAACM,kBAAtB,C,CACA;;AACA,IAAIC,QAAQ,GAAGX,OAAO,CAAE,gBAAF,CAAP,GAA8BW,QAA7C,C,CACA;;;AACA,IAAIC,SAAS,GAAGb,OAAO,CAACc,MAAR,CAAeD,SAA/B;AAEA,IAAIE,eAAe,GAAGC,MAAM,CAACC,MAAP,CAAe,IAAf,CAAtB;AACAF,eAAe,CAACG,EAAhB,GAAqB,IAArB;AACAH,eAAe,CAACI,EAAhB,GAAqB,KAArB;AACAJ,eAAe,CAACK,GAAhB,GAAsB,OAAtB;AACAL,eAAe,CAAE,MAAF,CAAf,GAA4BA,eAAe,CAACM,EAAhB,GAAqB,MAAjD;AACAN,eAAe,CAAE,MAAF,CAAf,GAA4B,MAA5B;AACAA,eAAe,CAAE,KAAF,CAAf,GAA2B,IAA3B;AACAA,eAAe,CAAE,MAAF,CAAf,GAA4B,IAA5B;AACAA,eAAe,CAAE,MAAF,CAAf,GAA4B,KAA5B;AACAA,eAAe,CAAE,KAAF,CAAf,GAA2B,OAA3B,C,CACA;;AACA,MAAMO,IAAI,GAAG,GAAb;AACA,MAAMC,IAAI,GAAG,GAAb,C,CACA;;AACA,MAAMC,SAAS,GAAG,2CAAlB;AACA,MAAMC,cAAc,GAAG,mDAAvB,C,CACA;;AACA,MAAMC,IAAI,GAAGV,MAAM,CAACC,MAAP,CAAe,IAAf,CAAb;AACAS,IAAI,CAAE,OAAF,CAAJ,GAAkB,IAAlB;AACAA,IAAI,CAAE,OAAF,CAAJ,GAAkB,IAAlB;AACAA,IAAI,CAAE,OAAF,CAAJ,GAAkB,IAAlB;AACAA,IAAI,CAAE,OAAF,CAAJ,GAAkB,IAAlB;AACAA,IAAI,CAAE,OAAF,CAAJ,GAAkB,IAAlB;AACAA,IAAI,CAAE,OAAF,CAAJ,GAAkB,IAAlB;AACAA,IAAI,CAAE,OAAF,CAAJ,GAAkB,IAAlB;AACAA,IAAI,CAAE,OAAF,CAAJ,GAAkB,IAAlB;AACAA,IAAI,CAAE,WAAF,CAAJ,GAAsB,IAAtB;AACAA,IAAI,CAAE,WAAF,CAAJ,GAAsB,IAAtB;AACAA,IAAI,CAAE,WAAF,CAAJ,GAAsB,IAAtB;AACAA,IAAI,CAAE,WAAF,CAAJ,GAAsB,IAAtB;AACAA,IAAI,CAAE,WAAF,CAAJ,GAAsB,IAAtB;AACAA,IAAI,CAAE,WAAF,CAAJ,GAAsB,IAAtB;AACAA,IAAI,CAAE,WAAF,CAAJ,GAAsB,IAAtB;AACAA,IAAI,CAAE,WAAF,CAAJ,GAAsB,IAAtB;AACAA,IAAI,CAAE,WAAF,CAAJ,GAAsB,IAAtB,C,CAEA;;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,IAAIC,SAAS,GAAG,YAAa;EAE3B;AACF;AACA;AACA;AACA;EACE,IAAIC,OAAO,GAAGZ,MAAM,CAACC,MAAP,CAAe,IAAf,CAAd,CAP2B,CAS3B;;EACA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;EACE,IAAIY,aAAa,GAAG,UAAWC,OAAX,EAAqB;IACvC,IAAK,CAAC9B,OAAO,CAAC+B,QAAR,CAAiBC,QAAjB,CAA2BF,OAA3B,CAAN,EAA6C;MAC3C,MAAMG,KAAK,CAAE,8EAA8EC,IAAI,CAACC,SAAL,CAAgBL,OAAhB,CAAhF,CAAX;IACD,CAHsC,CAIvC;;;IACA,KAAM,IAAIM,GAAV,IAAiBN,OAAjB,EAA2B5B,WAAW,CAAEW,SAAS,CAAEuB,GAAF,CAAX,CAAX,GAAkCN,OAAO,CAAEM,GAAF,CAAzC,CALY,CAKsC;;EAC9E,CAND,CA1B2B,CAgCxB;EAEH;;EACA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;EACE,IAAIC,YAAY,GAAG,YAAa;IAC9B;IACA,OAASH,IAAI,CAACI,KAAL,CAAYJ,IAAI,CAACC,SAAL,CAAgB;MAAEI,KAAK,EAAE,IAAT;MAAeC,MAAM,EAAE;IAAvB,CAAhB,CAAZ,CAAT;EACD,CAHD,CAjD2B,CAoDxB;EAEH;;EACA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;EACE,IAAIC,SAAS,GAAG,UAAWC,MAAX,EAAoB;IAClC,IAAIC,CAAJ,EAAOC,EAAP,EAAWC,CAAX;IACA,IAAIN,KAAJ;IACA,IAAIO,IAAJ;;IACA,KAAM,IAAIC,CAAC,GAAG,CAAR,EAAWC,IAAI,GAAGN,MAAM,CAACO,MAA/B,EAAuCF,CAAC,GAAGC,IAA3C,EAAiDD,CAAC,IAAI,CAAtD,EAA0D;MACxDJ,CAAC,GAAGD,MAAM,CAAEK,CAAF,CAAV;MACAF,CAAC,GAAGF,CAAC,CAACH,MAAN;MACAI,EAAE,GAAGD,CAAC,CAACO,KAAF,CAAS,CAAT,CAAL;MACAJ,IAAI,GAAGpB,IAAI,CAAEmB,CAAF,CAAX;MACA,IAAKC,IAAL,EAAYH,CAAC,CAACQ,GAAF,GAAQ,IAAR,CAL4C,CAMxD;;MACAZ,KAAK,GAAGxB,eAAe,CAAE8B,CAAF,CAAvB;;MACA,IAAKN,KAAL,EAAa;QACXI,CAAC,CAACJ,KAAF,GAAUA,KAAV;MACD,CAFD,MAEO;QACL;QACA,QAASI,CAAC,CAACQ,GAAF,CAAO,CAAP,CAAT;UACE,KAAK,GAAL;YACE,IAAOP,EAAE,IAAItB,IAAR,IAAoBsB,EAAE,IAAIrB,IAA/B,EAAwC;cACtCoB,CAAC,CAACJ,KAAF,GAAUM,CAAV;cACAF,CAAC,CAACQ,GAAF,GAAQ,KAAR;YACD,CAHD,MAGO;cACLR,CAAC,CAACJ,KAAF,GAAYI,CAAC,CAACQ,GAAF,CAAMF,MAAN,GAAe,CAAjB,GAAuBvC,YAAY,CAAEmC,CAAF,CAAnC,GAA2CA,CAArD;YACD;;YACD;;UACF,KAAK,GAAL;YACEF,CAAC,CAACJ,KAAF,GAAYI,CAAC,CAACQ,GAAF,CAAMF,MAAN,GAAe,CAAjB,GACMN,CAAC,CAACH,MAAF,KAAa,KAAf,GAAwB,IAAxB,GAA+BlC,YAAY,CAAEuC,CAAF,CAD/C,GAEEA,CAFZ;YAGA;;UACF,KAAK,GAAL;YACE,IAAOD,EAAE,IAAItB,IAAR,IAAoBsB,EAAE,IAAIrB,IAA/B,EAAwC;cACtCoB,CAAC,CAACJ,KAAF,GAAUM,CAAV;cACAF,CAAC,CAACQ,GAAF,GAAQ,KAAR;YACD,CAHD,MAGO;cACL;cACAR,CAAC,CAACJ,KAAF,GAAYI,CAAC,CAACQ,GAAF,KAAU,KAAV,IAAmBR,CAAC,CAACQ,GAAF,CAAMF,MAAN,GAAe,CAApC,GAA0CzC,YAAY,CAAEqC,CAAF,CAAtD,GAA8DA,CAAxE;YACD;;YACD;;UACF,KAAK,GAAL;YACEF,CAAC,CAACJ,KAAF,GAAUjC,YAAY,CAAEuC,CAAF,CAAtB;YACA;;UACF,QA1BF,CA2BI;;QA3BJ,CAFK,CA8BH;;MACH,CAzCuD,CAyCtD;;IACH;;IAED,OAAOH,MAAP;EACD,CAjDD,CAjE2B,CAkHxB;EAEH;;EACA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;EACE,IAAIU,GAAG,GAAG,UAAWV,MAAX,EAAoB;IAC5B;IACA,IAAIW,KAAK,GAAG,EAAZ,CAF4B,CAG5B;;IACA,IAAIV,CAAJ;;IACA,KAAM,IAAII,CAAC,GAAG,CAAR,EAAWC,IAAI,GAAGN,MAAM,CAACO,MAA/B,EAAuCF,CAAC,GAAGC,IAA3C,EAAiDD,CAAC,IAAI,CAAtD,EAA0D;MACxDJ,CAAC,GAAGD,MAAM,CAAEK,CAAF,CAAV,CADwD,CAExD;;MACAJ,CAAC,CAACH,MAAF,GAAW3B,SAAS,CAAE8B,CAAC,CAACO,KAAJ,CAApB;MACAG,KAAK,CAACC,IAAN,CAAYnD,gBAAgB,CAAEwC,CAAF,EAAKzC,WAAL,CAA5B;IACD;;IACDE,iBAAiB,CAAEsC,MAAF,EAAUW,KAAV,CAAjB,CAX4B,CAY5B;;IACAZ,SAAS,CAAEC,MAAF,CAAT;IACA,OAAOA,MAAP;EACD,CAfD,CAnJ2B,CAkKxB;EAEH;;EACA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;EACE,IAAIa,YAAY,GAAG,UAAWC,SAAX,EAAuB;IACxC;IACA,IAAIC,EAAE,GAAG,EAAT;IACA,IAAId,CAAJ;;IACA,KAAM,IAAII,CAAC,GAAG,CAAR,EAAWC,IAAI,GAAGQ,SAAS,CAACP,MAAlC,EAA0CF,CAAC,GAAGC,IAA9C,EAAoDD,CAAC,IAAI,CAAzD,EAA6D;MAC3DJ,CAAC,GAAGa,SAAS,CAAET,CAAF,CAAb;;MACA,IAAKvB,SAAS,CAACkC,IAAV,CAAgBf,CAAhB,CAAL,EAA2B;QACzBc,EAAE,CAACH,IAAH,CAAS;UAAEJ,KAAK,EAAEP,CAAT;UAAYS,GAAG,EAAE;QAAjB,CAAT;MACD,CAFD,MAEO,IAAK3B,cAAc,CAACiC,IAAf,CAAqBf,CAArB,CAAL,EAAgC;QACrCc,EAAE,CAACH,IAAH,CAAS;UAAEJ,KAAK,EAAEP,CAAT;UAAYS,GAAG,EAAE;QAAjB,CAAT;MACD,CAFM,MAEAK,EAAE,CAACH,IAAH,CAAS;QAAEJ,KAAK,EAAEP,CAAT;QAAYS,GAAG,EAAE;MAAjB,CAAT;IACR;;IAED,OAAOA,GAAG,CAAEK,EAAF,CAAV;EACD,CAdD,CAlM2B,CAgNxB;EAEH;;EACA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;EACE,IAAIE,WAAW,GAAG,UAAWC,QAAX,EAAsB;IACtC,IAAK,OAAOA,QAAP,KAAoB,QAAzB,EAAoC;MAClC,MAAM3B,KAAK,CAAE,sEAAsE,OAAO2B,QAA/E,CAAX;IACD;;IACD,OAAOR,GAAG,CAAExC,QAAQ,CAAEgD,QAAF,CAAV,CAAV;EACD,CALD,CA/O2B,CAoPxB;;;EAEHhC,OAAO,CAACC,aAAR,GAAwBA,aAAxB;EACAD,OAAO,CAACwB,GAAR,GAAcA,GAAd;EACAxB,OAAO,CAACiC,SAAR,GAAoBT,GAApB;EACAxB,OAAO,CAAC2B,YAAR,GAAuBA,YAAvB;EACA3B,OAAO,CAAC+B,WAAR,GAAsBA,WAAtB;EACA/B,OAAO,CAACS,YAAR,GAAuBA,YAAvB;EAEA,OAAOT,OAAP;AACD,CA9PD,C,CA8PG;;;AAEHkC,MAAM,CAACC,OAAP,GAAiBpC,SAAjB"},"metadata":{},"sourceType":"script"}