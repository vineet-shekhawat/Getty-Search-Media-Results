{"ast":null,"code":"//     wink-tokenizer\n//     Multilingual tokenizer that automatically tags each token with its type.\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of ‚Äúwink-tokenizer‚Äù.\n//\n//     Permission is hereby granted, free of charge, to any person obtaining a\n//     copy of this software and associated documentation files (the \"Software\"),\n//     to deal in the Software without restriction, including without limitation\n//     the rights to use, copy, modify, merge, publish, distribute, sublicense,\n//     and/or sell copies of the Software, and to permit persons to whom the\n//     Software is furnished to do so, subject to the following conditions:\n//\n//     The above copyright notice and this permission notice shall be included\n//     in all copies or substantial portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n//     OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n//     FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n//     LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n//     FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n//\nvar emojiRegex = require('emoji-regex');\n\nvar contractions = require('./eng-contractions.js');\n\nvar rgxSpaces = /\\s+/g; // Ordinals only for Latin like 1st, 2nd or 12th or 33rd.\n\nvar rgxOrdinalL1 = /1\\dth|[04-9]th|1st|2nd|3rd|[02-9]1st|[02-9]2nd|[02-9]3rd|[02-9][04-9]th|\\d+\\d[04-9]th|\\d+\\d1st|\\d+\\d2nd|\\d+\\d3rd/g; // Apart from detecting pure integers or decimals, also detect numbers containing\n// `. - / ,` so that dates, ip address, fractions and things like codes or part\n// numbers are also detected as numbers only. These regex will therefore detected\n// 8.8.8.8 or 12-12-1924 or 1,1,1,1.00 or 1/4 or 1/4/66/777 as numbers.\n// Latin-1 Numbers.\n\nvar rgxNumberL1 = /\\d+\\/\\d+|\\d(?:[\\.,-\\/]?\\d)*(?:\\.\\d+)?/g; // Devanagari Numbers.\n\nvar rgxNumberDV = /[\\u0966-\\u096F]+\\/[\\u0966-\\u096F]+|[\\u0966-\\u096F](?:[\\.,-\\/]?[\\u0966-\\u096F])*(?:\\.[\\u0966-\\u096F]+)?/g;\nvar rgxMention = /@\\w+/g; // Latin-1 Hashtags.\n// Include entire Latin-1 script and not just English alphas.\n\nvar rgxHashtagL1 = /#[a-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u00FF_][a-z0-9\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u00FF_]*/gi; // Devanagari Hashtags\n\nvar rgxHashtagDV = /#[\\u0900-\\u0963\\u0970-\\u097F_][\\u0900-\\u0963\\u0970-\\u097F\\u0966-\\u096F0-9_]*/gi; // EMail is EN character set.\n\nvar rgxEmail = /[-!#$%&'*+\\/=?^\\w{|}~](?:\\.?[-!#$%&'*+\\/=?^\\w`{|}~])*@[a-z0-9](?:-?\\.?[a-z0-9])*(?:\\.[a-z](?:-?[a-z0-9])*)+/gi; // Bitcoin, Ruble, Indian Rupee, Other Rupee, Dollar, Pound, Yen, Euro, Wong.\n\nvar rgxCurrency = /[‚Çø‚ÇΩ‚Çπ‚Ç®$¬£¬•‚Ç¨‚Ç©]/g; // These include both the punctuations: Latin-1 & Devanagari.\n\nvar rgxPunctuation = /[‚Äô'‚Äò‚Äô`‚Äú‚Äù\"\\[\\]\\(\\){}‚Ä¶,\\.!;\\?\\-:\\u0964\\u0965]/g;\nvar rgxQuotedPhrase = /\"[^\"]*\"/g; // NOTE: URL will support only EN character set for now.\n\nvar rgxURL = /(?:https?:\\/\\/)(?:[\\da-z\\.-]+)\\.(?:[a-z\\.]{2,6})(?:[\\/\\w\\.\\-\\?#=]*)*\\/?/gi;\nvar rgxEmoji = emojiRegex();\nvar rgxEmoticon = /:-?[dps\\*\\/\\[\\]{}\\(\\)]|;-?[/(/)d]|<3/gi;\nvar rgxTime = /(?:\\d|[01]\\d|2[0-3]):?(?:[0-5][0-9])?\\s?(?:[ap]\\.?m\\.?|hours|hrs)/gi; // Inlcude [Latin-1 Supplement Unicode Block](https://en.wikipedia.org/wiki/Latin-1_Supplement_(Unicode_block))\n\nvar rgxWordL1 = /[a-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u00FF][a-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u00FF']*/gi; // Define [Devanagari Unicode Block](https://unicode.org/charts/PDF/U0900.pdf)\n\nvar rgxWordDV = /[\\u0900-\\u094F\\u0951-\\u0963\\u0970-\\u097F]+/gi; // Symbols go here; including Om.\n\nvar rgxSymbol = /[\\u0950~@#%\\^\\+=\\*\\|\\/<>&]/g; // For detecting if the word is a potential contraction.\n\nvar rgxContraction = /'/; // Singular & Plural possessive\n\nvar rgxPosSingular = /([a-z]+)('s)$/i;\nvar rgxPosPlural = /([a-z]+s)(')$/i; // Regexes and their categories; used for tokenizing via match/split. The\n// sequence is *critical* for correct tokenization.\n\nvar rgxsMaster = [{\n  regex: rgxQuotedPhrase,\n  category: 'quoted_phrase'\n}, {\n  regex: rgxURL,\n  category: 'url'\n}, {\n  regex: rgxEmail,\n  category: 'email'\n}, {\n  regex: rgxMention,\n  category: 'mention'\n}, {\n  regex: rgxHashtagL1,\n  category: 'hashtag'\n}, {\n  regex: rgxHashtagDV,\n  category: 'hashtag'\n}, {\n  regex: rgxEmoji,\n  category: 'emoji'\n}, {\n  regex: rgxEmoticon,\n  category: 'emoticon'\n}, {\n  regex: rgxTime,\n  category: 'time'\n}, {\n  regex: rgxOrdinalL1,\n  category: 'ordinal'\n}, {\n  regex: rgxNumberL1,\n  category: 'number'\n}, {\n  regex: rgxNumberDV,\n  category: 'number'\n}, {\n  regex: rgxCurrency,\n  category: 'currency'\n}, {\n  regex: rgxWordL1,\n  category: 'word'\n}, {\n  regex: rgxWordDV,\n  category: 'word'\n}, {\n  regex: rgxPunctuation,\n  category: 'punctuation'\n}, {\n  regex: rgxSymbol,\n  category: 'symbol'\n}]; // Used to generate finger print from the tokens.\n// NOTE: this variable is being reset in `defineConfig()`.\n\nvar fingerPrintCodes = {\n  emoticon: 'c',\n  email: 'e',\n  emoji: 'j',\n  hashtag: 'h',\n  mention: 'm',\n  number: 'n',\n  ordinal: 'o',\n  quoted_phrase: 'q',\n  // eslint-disable-line camelcase\n  currency: 'r',\n  // symbol: 's',\n  time: 't',\n  url: 'u',\n  word: 'w',\n  alien: 'z'\n}; // ### tokenizer\n\n/**\n *\n * Creates an instance of {@link Tokenizer}.\n *\n * @return {Tokenizer} object conatining set of API methods for tokenizing a sentence\n * and defining configuration, plugin etc.\n * @example\n * // Load wink tokenizer.\n * var tokenizer = require( 'wink-tokenizer' );\n * // Create your instance of wink tokenizer.\n * var myTokenizer = tokenizer();\n*/\n\nvar tokenizer = function () {\n  // Default configuration: most comprehensive tokenization. Make deep copy!\n  var rgxs = rgxsMaster.slice(0); // The result of last call to `tokenize()` is retained here.\n\n  var finalTokens = []; // Returned!\n\n  /**\n   * @classdesc Tokenizer class\n   * @class Tokenizer\n   * @hideconstructor\n   */\n\n  var methods = Object.create(null); // ### manageContraction\n\n  /**\n   *\n   * Splits a contractions into words by first trying a lookup in strandard\n   * `contractions`; if the lookup fails, it checks for possessive in `'s` or\n   * `s'` forms and separates the possesive part from the word. Otherwise the\n   * contraction is treated as a normal word and no splitting occurs.\n   *\n   * @param {string} word that could be a potential conraction.\n   * @param {object[]} tokens where the outcome is pushed.\n   * @return {object[]} updated tokens according to the `word.`\n   * @private\n  */\n\n  var manageContraction = function (word, tokens) {\n    var ct = contractions[word];\n    var matches;\n\n    if (ct === undefined) {\n      // Try possesive of sigular & plural forms\n      matches = word.match(rgxPosSingular);\n\n      if (matches) {\n        tokens.push({\n          value: matches[1],\n          tag: 'word'\n        });\n        tokens.push({\n          value: matches[2],\n          tag: 'word'\n        });\n      } else {\n        matches = word.match(rgxPosPlural);\n\n        if (matches) {\n          tokens.push({\n            value: matches[1],\n            tag: 'word'\n          });\n          tokens.push({\n            value: matches[2],\n            tag: 'word'\n          });\n        } else tokens.push({\n          value: word,\n          tag: 'word'\n        });\n      }\n    } else {\n      // Manage via lookup; ensure cloning!\n      tokens.push(Object.assign({}, ct[0]));\n      tokens.push(Object.assign({}, ct[1]));\n      if (ct[2]) tokens.push(Object.assign({}, ct[2]));\n    }\n\n    return tokens;\n  }; // manageContraction()\n  // ### tokenizeTextUnit\n\n  /**\n   *\n   * Attempts to tokenize the input `text` using the `rgxSplit`. The tokenization\n   * is carried out by combining the regex matches and splits in the right sequence.\n   * The matches are the *real tokens*, whereas splits are text units that are\n   * tokenized in later rounds! The real tokens (i.e. matches) are pushed as\n   * `object` and splits as `string`.\n   *\n   * @param {string} text unit that is to be tokenized.\n   * @param {object} rgxSplit object containing the regex and it's category.\n   * @return {array} of tokens.\n   * @private\n  */\n\n\n  var tokenizeTextUnit = function (text, rgxSplit) {\n    // Regex matches go here; note each match is a token and has the same tag\n    // as of regex's category.\n    var matches = text.match(rgxSplit.regex); // Balance is \"what needs to be tokenized\".\n\n    var balance = text.split(rgxSplit.regex); // The result, in form of combination of tokens & matches, is captured here.\n\n    var tokens = []; // The tag;\n\n    var tag = rgxSplit.category; // Helper variables.\n\n    var aword,\n        i,\n        imax,\n        k = 0,\n        t; // Combine tokens & matches in the following pattern [ b0 m0 b1 m1 ... ]\n\n    matches = matches ? matches : [];\n\n    for (i = 0, imax = balance.length; i < imax; i += 1) {\n      t = balance[i];\n      t = t.trim();\n      if (t) tokens.push(t);\n\n      if (k < matches.length) {\n        if (tag === 'word') {\n          // Tag type `word` token may have a contraction.\n          aword = matches[k];\n\n          if (rgxContraction.test(aword)) {\n            tokens = manageContraction(aword, tokens);\n          } else {\n            // Means there is no contraction.\n            tokens.push({\n              value: aword,\n              tag: tag\n            });\n          }\n        } else tokens.push({\n          value: matches[k],\n          tag: tag\n        });\n      }\n\n      k += 1;\n    }\n\n    return tokens;\n  }; // tokenizeTextUnit()\n  // ### tokenizeTextRecursively\n\n  /**\n   *\n   * Tokenizes the input text recursively using the array of `regexes` and then\n   * the `tokenizeTextUnit()` function. If (or whenever) the `regexes` becomes\n   * empty, it simply splits the text on non-word characters instead of using\n   * the `tokenizeTextUnit()` function.\n   *\n   * @param {string} text unit that is to be tokenized.\n   * @param {object} regexes object containing the regex and it's category.\n   * @return {undefined} nothing!\n   * @private\n  */\n\n\n  var tokenizeTextRecursively = function (text, regexes) {\n    var sentence = text.trim();\n    var tokens = [];\n    var i, imax;\n\n    if (!regexes.length) {\n      // No regex left, split on `spaces` and tag every token as **alien**.\n      text.split(rgxSpaces).forEach(function (tkn) {\n        finalTokens.push({\n          value: tkn.trim(),\n          tag: 'alien'\n        });\n      });\n      return;\n    }\n\n    var rgx = regexes[0];\n    tokens = tokenizeTextUnit(sentence, rgx);\n\n    for (i = 0, imax = tokens.length; i < imax; i += 1) {\n      if (typeof tokens[i] === 'string') {\n        // Strings become candidates for further tokenization.\n        tokenizeTextRecursively(tokens[i], regexes.slice(1));\n      } else {\n        finalTokens.push(tokens[i]);\n      }\n    }\n  }; // tokenizeTextRecursively()\n  // ### defineConfig\n\n  /**\n   *\n   * Defines the configuration in terms of the types of token that will be\n   * extracted by [`tokenize()`](#tokenize) method. Note by default, all types\n   * of tokens will be detected and tagged automatically.\n   *\n   * @method Tokenizer#defineConfig\n   * @param {object} config It defines 0 or more properties from the list of\n   * **14** properties. A true value for a property ensures tokenization\n   * for that type of text; whereas false value will mean that the tokenization of that\n   * type of text will not be attempted. It also **resets** the effect of any previous\n   * call(s) to the [`addRegex()`](#addregex) API.\n   *\n   * *An empty config object is equivalent to splitting on spaces. Whatever tokens\n   * are created like this are tagged as **alien** and **`z`** is the\n   * [finger print](#gettokensfp) code of this token type.*\n   *\n   * The table below gives the name of each property and it's description including\n   * examples. The character with in paranthesis is the [finger print](#gettokensfp) code for the\n   * token of that type.\n   * @param {boolean} [config.currency=true] such as **$** or **¬£** symbols (**`r`**)\n   * @param {boolean} [config.email=true] for example **john@acme.com** or **superman1@gmail.com** (**`e`**)\n   * @param {boolean} [config.emoji=true] any standard unicode emojis e.g. üòä or üòÇ or üéâ (**`j`**)\n   * @param {boolean} [config.emoticon=true] common emoticons such as **`:-)`** or **`:D`** (**`c`**)\n   * @param {boolean} [config.hashtag=true] hash tags such as **`#happy`** or **`#followme`** (**`h`**)\n   * @param {boolean} [config.number=true] any integer, decimal number, fractions such as **19**, **2.718**\n   * or **1/4** and numerals containing \"**`, - / .`**\", for example 12-12-1924 (**`n`**)\n   * @param {boolean} [config.ordinal=true] ordinals like **1st**, **2nd**, **3rd**, **4th** or **12th** or **91st** (**`o`**)\n   * @param {boolean} [config.punctuation=true] common punctuation such as **`?`** or **`,`**\n   * ( token becomes fingerprint )\n   * @param {boolean} [config.quoted_phrase=false] any **\"quoted text\"** in the sentence. _Note: its default value is **false**._ (**`q`**)\n   * @param {boolean} [config.symbol=true] for example **`~`** or **`+`** or **`&`** or **`%`** or **`/`** ( token becomes fingerprint )\n   * @param {boolean} [config.time=true] common representation of time such as **4pm** or **16:00 hours** (**`t`**)\n   * @param {boolean} [config.mention=true] **@mention**  as in github or twitter (**`m`**)\n   * @param {boolean} [config.url=true] URL such as **https://github.com** (**`u`**)\n   * @param {boolean} [config.word=true] word such as **faster** or **r√©sum√©** or **pr√©venir** (**`w`**)\n   * @return {number} number of properties set to true from the list of above 13.\n   * @example\n   * // Do not tokenize & tag @mentions.\n   * var myTokenizer.defineConfig( { mention: false } );\n   * // -> 13\n   * // Only tokenize words as defined above.\n   * var myTokenizer.defineConfig( {} );\n   * // -> 0\n  */\n\n\n  var defineConfig = function (config) {\n    if (typeof config === 'object' && Object.keys(config).length) {\n      rgxs = rgxsMaster.filter(function (rgx) {\n        // Config for the Category of `rgx`.\n        var cc = config[rgx.category]; // Means `undefined` & `null` values are taken as true; otherwise\n        // standard **truthy** and **falsy** interpretation applies!!\n\n        return cc === undefined || cc === null || !!cc;\n      });\n    } else rgxs = []; // Count normalized length i.e. ignore multi-script entries.\n\n\n    const uniqueCats = Object.create(null);\n    rgxs.forEach(function (rgx) {\n      uniqueCats[rgx.category] = true;\n    }); // Reset the `fingerPrintCodes` variable.\n\n    fingerPrintCodes = {\n      emoticon: 'c',\n      email: 'e',\n      emoji: 'j',\n      hashtag: 'h',\n      mention: 'm',\n      number: 'n',\n      ordinal: 'o',\n      quoted_phrase: 'q',\n      // eslint-disable-line camelcase\n      currency: 'r',\n      // symbol: 's',\n      time: 't',\n      url: 'u',\n      word: 'w',\n      alien: 'z'\n    };\n    return Object.keys(uniqueCats).length;\n  }; // defineConfig()\n  // ### tokenize\n\n  /**\n   *\n   * Tokenizes the input `sentence` using the configuration specified via\n   * [`defineConfig()`](#defineconfig).\n   * Common contractions and possessive nouns are split into 2 separate tokens;\n   * for example **I'll** splits as `'I'` and `'\\'ll'` or **won't** splits as\n   * `'wo'` and `'n\\'t'`.\n   *\n   * @method Tokenizer#tokenize\n   * @param {string} sentence the input sentence.\n   * @return {object[]} of tokens; each one of them is an object with 2-keys viz.\n   * `value` and its `tag` identifying the type of the token.\n   * @example\n   * var s = 'For detailed API docs, check out http://winkjs.org/wink-regression-tree/ URL!';\n   * myTokenizer.tokenize( s );\n   * // -> [ { value: 'For', tag: 'word' },\n   * //      { value: 'detailed', tag: 'word' },\n   * //      { value: 'API', tag: 'word' },\n   * //      { value: 'docs', tag: 'word' },\n   * //      { value: ',', tag: 'punctuation' },\n   * //      { value: 'check', tag: 'word' },\n   * //      { value: 'out', tag: 'word' },\n   * //      { value: 'http://winkjs.org/wink-regression-tree/', tag: 'url' },\n   * //      { value: 'URL', tag: 'word' },\n   * //      { value: '!', tag: 'punctuation' } ]\n  */\n\n\n  var tokenize = function (sentence) {\n    finalTokens = [];\n    tokenizeTextRecursively(sentence, rgxs);\n    return finalTokens;\n  }; // tokenize()\n  // ### getTokensFP\n\n  /**\n   *\n   * Returns the finger print of the tokens generated by the last call to\n   * [`tokenize()`](#tokenize). A finger print is a string created by sequentially\n   * joining the unique code of each token's type. Refer to table given under\n   * [`defineConfig()`](#defineconfig) for values of these codes.\n   *\n   * A finger print is extremely useful in spotting patterns present in the sentence\n   * using `regexes`, which is otherwise a complex and time consuming task.\n   *\n   * @method Tokenizer#getTokensFP\n   * @return {string} finger print of tokens generated by the last call to `tokenize()`.\n   * @example\n   * // Generate finger print of sentence given in the previous example\n   * // under tokenize().\n   * myTokenizer.getTokensFP();\n   * // -> 'wwww,wwuw!'\n  */\n\n\n  var getTokensFP = function () {\n    var fp = [];\n    finalTokens.forEach(function (t) {\n      fp.push(fingerPrintCodes[t.tag] ? fingerPrintCodes[t.tag] : t.value);\n    });\n    return fp.join('');\n  }; // getFingerprint()\n  // ### addTag\n\n\n  var addTag = function (name, fingerprintCode) {\n    if (fingerPrintCodes[name]) {\n      throw new Error('Tag ' + name + ' already exists');\n    }\n\n    fingerPrintCodes[name] = fingerprintCode;\n  }; // addTag()\n  // ### addRegex\n\n  /**\n   * Adds a regex for parsing a new type of token. This regex can either be mapped\n   * to an existing tag or it allows creation of a new tag along with its finger print.\n   * The uniqueness of the [finger prints](#defineconfig) have to ensured by the user.\n   *\n   * *The added regex(s) will supersede the internal parsing.*\n   *\n   * @method Tokenizer#addRegex\n   * @param {RegExp} regex the new regular expression.\n   * @param {string} tag tokens matching the `regex` will be assigned this tag.\n   * @param {string} [fingerprintCode=undefined] required if adding a new\n   * tag; ignored if using an existing tag.\n   * @return {void} nothing!\n   * @example\n   * // Adding a regex for an existing tag\n   * myTokenizer.addRegex( /\\(oo\\)/gi, 'emoticon' );\n   * myTokenizer.tokenize( '(oo) Hi!' )\n   * // -> [ { value: '(oo)', tag: 'emoticon' },\n   * //      { value: 'Hi', tag: 'word' },\n   * //      { value: '!', tag: 'punctuation' } ]\n   *\n   * // Adding a regex to parse a new token type\n   * myTokenizer.addRegex( /hello/gi, 'greeting', 'g' );\n   * myTokenizer.tokenize( 'hello, how are you?' );\n   * // -> [ { value: 'hello', tag: 'greeting' },\n   * //      { value: ',', tag: 'punctuation' },\n   * //      { value: 'how', tag: 'word' },\n   * //      { value: 'are', tag: 'word' },\n   * //      { value: 'you', tag: 'word' },\n   * //      { value: '?', tag: 'punctuation' } ]\n   * // Notice how \"hello\" is now tagged as \"greeting\" and not as \"word\".\n   *\n   * // Using definConfig will reset the above!\n   * myTokenizer.defineConfig( { word: true } );\n   * myTokenizer.tokenize( 'hello, how are you?' );\n   * // -> [ { value: 'hello', tag: 'word' },\n   * //      { value: ',', tag: 'punctuation' },\n   * //      { value: 'how', tag: 'word' },\n   * //      { value: 'are', tag: 'word' },\n   * //      { value: 'you', tag: 'word' },\n   * //      { value: '?', tag: 'punctuation' } ]\n  */\n\n\n  var addRegex = function (regex, tag, fingerprintCode) {\n    if (!fingerPrintCodes[tag] && !fingerprintCode) {\n      throw new Error('Tag ' + tag + ' doesn\\'t exist; Provide a \\'fingerprintCode\\' to add it as a tag.');\n    } else if (!fingerPrintCodes[tag]) {\n      addTag(tag, fingerprintCode);\n    }\n\n    rgxs.unshift({\n      regex: regex,\n      category: tag\n    });\n  }; // addRegex()\n  // Set quoted_phrase as false becuase mostly it is not required.\n\n\n  defineConfig({\n    quoted_phrase: false\n  }); // eslint-disable-line camelcase\n\n  methods.defineConfig = defineConfig;\n  methods.tokenize = tokenize;\n  methods.getTokensFP = getTokensFP;\n  methods.addTag = addTag;\n  methods.addRegex = addRegex;\n  return methods;\n};\n\nmodule.exports = tokenizer;","map":{"version":3,"names":["emojiRegex","require","contractions","rgxSpaces","rgxOrdinalL1","rgxNumberL1","rgxNumberDV","rgxMention","rgxHashtagL1","rgxHashtagDV","rgxEmail","rgxCurrency","rgxPunctuation","rgxQuotedPhrase","rgxURL","rgxEmoji","rgxEmoticon","rgxTime","rgxWordL1","rgxWordDV","rgxSymbol","rgxContraction","rgxPosSingular","rgxPosPlural","rgxsMaster","regex","category","fingerPrintCodes","emoticon","email","emoji","hashtag","mention","number","ordinal","quoted_phrase","currency","time","url","word","alien","tokenizer","rgxs","slice","finalTokens","methods","Object","create","manageContraction","tokens","ct","matches","undefined","match","push","value","tag","assign","tokenizeTextUnit","text","rgxSplit","balance","split","aword","i","imax","k","t","length","trim","test","tokenizeTextRecursively","regexes","sentence","forEach","tkn","rgx","defineConfig","config","keys","filter","cc","uniqueCats","tokenize","getTokensFP","fp","join","addTag","name","fingerprintCode","Error","addRegex","unshift","module","exports"],"sources":["D:/Getty-Search-Media-Results/node_modules/wink-tokenizer/src/wink-tokenizer.js"],"sourcesContent":["//     wink-tokenizer\n//     Multilingual tokenizer that automatically tags each token with its type.\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of ‚Äúwink-tokenizer‚Äù.\n//\n//     Permission is hereby granted, free of charge, to any person obtaining a\n//     copy of this software and associated documentation files (the \"Software\"),\n//     to deal in the Software without restriction, including without limitation\n//     the rights to use, copy, modify, merge, publish, distribute, sublicense,\n//     and/or sell copies of the Software, and to permit persons to whom the\n//     Software is furnished to do so, subject to the following conditions:\n//\n//     The above copyright notice and this permission notice shall be included\n//     in all copies or substantial portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n//     OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n//     FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n//     LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n//     FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\nvar emojiRegex = require( 'emoji-regex' );\nvar contractions = require( './eng-contractions.js' );\nvar rgxSpaces = /\\s+/g;\n// Ordinals only for Latin like 1st, 2nd or 12th or 33rd.\nvar rgxOrdinalL1 = /1\\dth|[04-9]th|1st|2nd|3rd|[02-9]1st|[02-9]2nd|[02-9]3rd|[02-9][04-9]th|\\d+\\d[04-9]th|\\d+\\d1st|\\d+\\d2nd|\\d+\\d3rd/g;\n// Apart from detecting pure integers or decimals, also detect numbers containing\n// `. - / ,` so that dates, ip address, fractions and things like codes or part\n// numbers are also detected as numbers only. These regex will therefore detected\n// 8.8.8.8 or 12-12-1924 or 1,1,1,1.00 or 1/4 or 1/4/66/777 as numbers.\n// Latin-1 Numbers.\nvar rgxNumberL1 = /\\d+\\/\\d+|\\d(?:[\\.,-\\/]?\\d)*(?:\\.\\d+)?/g;\n// Devanagari Numbers.\nvar rgxNumberDV = /[\\u0966-\\u096F]+\\/[\\u0966-\\u096F]+|[\\u0966-\\u096F](?:[\\.,-\\/]?[\\u0966-\\u096F])*(?:\\.[\\u0966-\\u096F]+)?/g;\nvar rgxMention = /@\\w+/g;\n// Latin-1 Hashtags.\n// Include entire Latin-1 script and not just English alphas.\nvar rgxHashtagL1 = /#[a-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u00FF_][a-z0-9\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u00FF_]*/gi;\n// Devanagari Hashtags\nvar rgxHashtagDV = /#[\\u0900-\\u0963\\u0970-\\u097F_][\\u0900-\\u0963\\u0970-\\u097F\\u0966-\\u096F0-9_]*/gi;\n// EMail is EN character set.\nvar rgxEmail = /[-!#$%&'*+\\/=?^\\w{|}~](?:\\.?[-!#$%&'*+\\/=?^\\w`{|}~])*@[a-z0-9](?:-?\\.?[a-z0-9])*(?:\\.[a-z](?:-?[a-z0-9])*)+/gi;\n// Bitcoin, Ruble, Indian Rupee, Other Rupee, Dollar, Pound, Yen, Euro, Wong.\nvar rgxCurrency = /[‚Çø‚ÇΩ‚Çπ‚Ç®$¬£¬•‚Ç¨‚Ç©]/g;\n// These include both the punctuations: Latin-1 & Devanagari.\nvar rgxPunctuation = /[‚Äô'‚Äò‚Äô`‚Äú‚Äù\"\\[\\]\\(\\){}‚Ä¶,\\.!;\\?\\-:\\u0964\\u0965]/g;\nvar rgxQuotedPhrase = /\"[^\"]*\"/g;\n// NOTE: URL will support only EN character set for now.\nvar rgxURL = /(?:https?:\\/\\/)(?:[\\da-z\\.-]+)\\.(?:[a-z\\.]{2,6})(?:[\\/\\w\\.\\-\\?#=]*)*\\/?/gi;\nvar rgxEmoji = emojiRegex();\nvar rgxEmoticon = /:-?[dps\\*\\/\\[\\]{}\\(\\)]|;-?[/(/)d]|<3/gi;\nvar rgxTime = /(?:\\d|[01]\\d|2[0-3]):?(?:[0-5][0-9])?\\s?(?:[ap]\\.?m\\.?|hours|hrs)/gi;\n// Inlcude [Latin-1 Supplement Unicode Block](https://en.wikipedia.org/wiki/Latin-1_Supplement_(Unicode_block))\nvar rgxWordL1 = /[a-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u00FF][a-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u00FF']*/gi;\n// Define [Devanagari Unicode Block](https://unicode.org/charts/PDF/U0900.pdf)\nvar rgxWordDV = /[\\u0900-\\u094F\\u0951-\\u0963\\u0970-\\u097F]+/gi;\n// Symbols go here; including Om.\nvar rgxSymbol = /[\\u0950~@#%\\^\\+=\\*\\|\\/<>&]/g;\n// For detecting if the word is a potential contraction.\nvar rgxContraction = /'/;\n// Singular & Plural possessive\nvar rgxPosSingular = /([a-z]+)('s)$/i;\nvar rgxPosPlural = /([a-z]+s)(')$/i;\n// Regexes and their categories; used for tokenizing via match/split. The\n// sequence is *critical* for correct tokenization.\nvar rgxsMaster = [\n  { regex: rgxQuotedPhrase, category: 'quoted_phrase' },\n  { regex: rgxURL, category: 'url' },\n  { regex: rgxEmail, category: 'email' },\n  { regex: rgxMention, category: 'mention' },\n  { regex: rgxHashtagL1, category: 'hashtag' },\n  { regex: rgxHashtagDV, category: 'hashtag' },\n  { regex: rgxEmoji, category: 'emoji' },\n  { regex: rgxEmoticon, category: 'emoticon' },\n  { regex: rgxTime, category: 'time' },\n  { regex: rgxOrdinalL1, category: 'ordinal' },\n  { regex: rgxNumberL1, category: 'number' },\n  { regex: rgxNumberDV, category: 'number' },\n  { regex: rgxCurrency, category: 'currency' },\n  { regex: rgxWordL1, category: 'word' },\n  { regex: rgxWordDV, category: 'word' },\n  { regex: rgxPunctuation, category: 'punctuation' },\n  { regex: rgxSymbol, category: 'symbol' }\n];\n\n// Used to generate finger print from the tokens.\n// NOTE: this variable is being reset in `defineConfig()`.\nvar fingerPrintCodes = {\n  emoticon: 'c',\n  email: 'e',\n  emoji: 'j',\n  hashtag: 'h',\n  mention: 'm',\n  number: 'n',\n  ordinal: 'o',\n  quoted_phrase: 'q', // eslint-disable-line camelcase\n  currency: 'r',\n  // symbol: 's',\n  time: 't',\n  url: 'u',\n  word: 'w',\n  alien: 'z'\n};\n\n// ### tokenizer\n/**\n *\n * Creates an instance of {@link Tokenizer}.\n *\n * @return {Tokenizer} object conatining set of API methods for tokenizing a sentence\n * and defining configuration, plugin etc.\n * @example\n * // Load wink tokenizer.\n * var tokenizer = require( 'wink-tokenizer' );\n * // Create your instance of wink tokenizer.\n * var myTokenizer = tokenizer();\n*/\nvar tokenizer = function () {\n  // Default configuration: most comprehensive tokenization. Make deep copy!\n  var rgxs = rgxsMaster.slice( 0 );\n  // The result of last call to `tokenize()` is retained here.\n  var finalTokens = [];\n  // Returned!\n\n  /**\n   * @classdesc Tokenizer class\n   * @class Tokenizer\n   * @hideconstructor\n   */\n  var methods = Object.create( null );\n\n  // ### manageContraction\n  /**\n   *\n   * Splits a contractions into words by first trying a lookup in strandard\n   * `contractions`; if the lookup fails, it checks for possessive in `'s` or\n   * `s'` forms and separates the possesive part from the word. Otherwise the\n   * contraction is treated as a normal word and no splitting occurs.\n   *\n   * @param {string} word that could be a potential conraction.\n   * @param {object[]} tokens where the outcome is pushed.\n   * @return {object[]} updated tokens according to the `word.`\n   * @private\n  */\n  var manageContraction = function ( word, tokens ) {\n    var ct = contractions[ word ];\n    var matches;\n    if ( ct === undefined ) {\n      // Try possesive of sigular & plural forms\n      matches = word.match( rgxPosSingular );\n      if ( matches ) {\n        tokens.push( { value: matches[ 1 ], tag: 'word' } );\n        tokens.push( { value: matches[ 2 ], tag: 'word' } );\n      } else {\n        matches = word.match( rgxPosPlural );\n        if ( matches ) {\n          tokens.push( { value: matches[ 1 ], tag: 'word' } );\n          tokens.push( { value: matches[ 2 ], tag: 'word' } );\n        } else tokens.push( { value: word, tag: 'word' } );\n      }\n    } else {\n      // Manage via lookup; ensure cloning!\n      tokens.push( Object.assign( {}, ct[ 0 ] ) );\n      tokens.push( Object.assign( {}, ct[ 1 ] ) );\n      if ( ct[ 2 ] ) tokens.push( Object.assign( {}, ct[ 2 ] ) );\n    }\n    return tokens;\n  }; // manageContraction()\n\n  // ### tokenizeTextUnit\n  /**\n   *\n   * Attempts to tokenize the input `text` using the `rgxSplit`. The tokenization\n   * is carried out by combining the regex matches and splits in the right sequence.\n   * The matches are the *real tokens*, whereas splits are text units that are\n   * tokenized in later rounds! The real tokens (i.e. matches) are pushed as\n   * `object` and splits as `string`.\n   *\n   * @param {string} text unit that is to be tokenized.\n   * @param {object} rgxSplit object containing the regex and it's category.\n   * @return {array} of tokens.\n   * @private\n  */\n  var tokenizeTextUnit = function ( text, rgxSplit ) {\n    // Regex matches go here; note each match is a token and has the same tag\n    // as of regex's category.\n    var matches = text.match( rgxSplit.regex );\n    // Balance is \"what needs to be tokenized\".\n    var balance = text.split( rgxSplit.regex );\n    // The result, in form of combination of tokens & matches, is captured here.\n    var tokens = [];\n    // The tag;\n    var tag = rgxSplit.category;\n    // Helper variables.\n    var aword,\n        i,\n        imax,\n        k = 0,\n        t;\n\n    // Combine tokens & matches in the following pattern [ b0 m0 b1 m1 ... ]\n    matches = ( matches ) ? matches : [];\n    for ( i = 0, imax = balance.length; i < imax; i += 1 ) {\n      t = balance[ i ];\n      t = t.trim();\n      if ( t ) tokens.push( t );\n      if ( k < matches.length ) {\n        if ( tag === 'word' ) {\n          // Tag type `word` token may have a contraction.\n          aword = matches[ k ];\n          if ( rgxContraction.test( aword ) ) {\n            tokens = manageContraction( aword, tokens );\n          } else {\n            // Means there is no contraction.\n            tokens.push( { value: aword, tag: tag } );\n          }\n        } else tokens.push( { value: matches[ k ], tag: tag } );\n      }\n      k += 1;\n    }\n\n    return ( tokens );\n  }; // tokenizeTextUnit()\n\n  // ### tokenizeTextRecursively\n  /**\n   *\n   * Tokenizes the input text recursively using the array of `regexes` and then\n   * the `tokenizeTextUnit()` function. If (or whenever) the `regexes` becomes\n   * empty, it simply splits the text on non-word characters instead of using\n   * the `tokenizeTextUnit()` function.\n   *\n   * @param {string} text unit that is to be tokenized.\n   * @param {object} regexes object containing the regex and it's category.\n   * @return {undefined} nothing!\n   * @private\n  */\n  var tokenizeTextRecursively = function ( text, regexes ) {\n    var sentence = text.trim();\n    var tokens = [];\n    var i, imax;\n\n    if ( !regexes.length ) {\n      // No regex left, split on `spaces` and tag every token as **alien**.\n      text.split( rgxSpaces ).forEach( function ( tkn ) {\n        finalTokens.push( { value: tkn.trim(), tag: 'alien' } );\n      } );\n      return;\n    }\n\n    var rgx = regexes[ 0 ];\n    tokens = tokenizeTextUnit( sentence, rgx );\n\n    for ( i = 0, imax = tokens.length; i < imax; i += 1 ) {\n      if ( typeof tokens[ i ] === 'string' ) {\n        // Strings become candidates for further tokenization.\n        tokenizeTextRecursively( tokens[ i ], regexes.slice( 1 ) );\n      } else {\n        finalTokens.push( tokens[ i ] );\n      }\n    }\n  }; // tokenizeTextRecursively()\n\n  // ### defineConfig\n  /**\n   *\n   * Defines the configuration in terms of the types of token that will be\n   * extracted by [`tokenize()`](#tokenize) method. Note by default, all types\n   * of tokens will be detected and tagged automatically.\n   *\n   * @method Tokenizer#defineConfig\n   * @param {object} config It defines 0 or more properties from the list of\n   * **14** properties. A true value for a property ensures tokenization\n   * for that type of text; whereas false value will mean that the tokenization of that\n   * type of text will not be attempted. It also **resets** the effect of any previous\n   * call(s) to the [`addRegex()`](#addregex) API.\n   *\n   * *An empty config object is equivalent to splitting on spaces. Whatever tokens\n   * are created like this are tagged as **alien** and **`z`** is the\n   * [finger print](#gettokensfp) code of this token type.*\n   *\n   * The table below gives the name of each property and it's description including\n   * examples. The character with in paranthesis is the [finger print](#gettokensfp) code for the\n   * token of that type.\n   * @param {boolean} [config.currency=true] such as **$** or **¬£** symbols (**`r`**)\n   * @param {boolean} [config.email=true] for example **john@acme.com** or **superman1@gmail.com** (**`e`**)\n   * @param {boolean} [config.emoji=true] any standard unicode emojis e.g. üòä or üòÇ or üéâ (**`j`**)\n   * @param {boolean} [config.emoticon=true] common emoticons such as **`:-)`** or **`:D`** (**`c`**)\n   * @param {boolean} [config.hashtag=true] hash tags such as **`#happy`** or **`#followme`** (**`h`**)\n   * @param {boolean} [config.number=true] any integer, decimal number, fractions such as **19**, **2.718**\n   * or **1/4** and numerals containing \"**`, - / .`**\", for example 12-12-1924 (**`n`**)\n   * @param {boolean} [config.ordinal=true] ordinals like **1st**, **2nd**, **3rd**, **4th** or **12th** or **91st** (**`o`**)\n   * @param {boolean} [config.punctuation=true] common punctuation such as **`?`** or **`,`**\n   * ( token becomes fingerprint )\n   * @param {boolean} [config.quoted_phrase=false] any **\"quoted text\"** in the sentence. _Note: its default value is **false**._ (**`q`**)\n   * @param {boolean} [config.symbol=true] for example **`~`** or **`+`** or **`&`** or **`%`** or **`/`** ( token becomes fingerprint )\n   * @param {boolean} [config.time=true] common representation of time such as **4pm** or **16:00 hours** (**`t`**)\n   * @param {boolean} [config.mention=true] **@mention**  as in github or twitter (**`m`**)\n   * @param {boolean} [config.url=true] URL such as **https://github.com** (**`u`**)\n   * @param {boolean} [config.word=true] word such as **faster** or **r√©sum√©** or **pr√©venir** (**`w`**)\n   * @return {number} number of properties set to true from the list of above 13.\n   * @example\n   * // Do not tokenize & tag @mentions.\n   * var myTokenizer.defineConfig( { mention: false } );\n   * // -> 13\n   * // Only tokenize words as defined above.\n   * var myTokenizer.defineConfig( {} );\n   * // -> 0\n  */\n  var defineConfig = function ( config ) {\n    if ( typeof config === 'object' && Object.keys( config ).length ) {\n      rgxs = rgxsMaster.filter( function ( rgx ) {\n        // Config for the Category of `rgx`.\n        var cc = config[ rgx.category ];\n        // Means `undefined` & `null` values are taken as true; otherwise\n        // standard **truthy** and **falsy** interpretation applies!!\n        return ( cc === undefined || cc === null || !!cc );\n      } );\n    } else rgxs = [];\n    // Count normalized length i.e. ignore multi-script entries.\n    const uniqueCats = Object.create( null );\n    rgxs.forEach( function ( rgx ) {\n      uniqueCats[ rgx.category ] = true;\n    } );\n    // Reset the `fingerPrintCodes` variable.\n    fingerPrintCodes = {\n      emoticon: 'c',\n      email: 'e',\n      emoji: 'j',\n      hashtag: 'h',\n      mention: 'm',\n      number: 'n',\n      ordinal: 'o',\n      quoted_phrase: 'q', // eslint-disable-line camelcase\n      currency: 'r',\n      // symbol: 's',\n      time: 't',\n      url: 'u',\n      word: 'w',\n      alien: 'z'\n    };\n    return ( ( Object.keys( uniqueCats ) ).length );\n  }; // defineConfig()\n\n  // ### tokenize\n  /**\n   *\n   * Tokenizes the input `sentence` using the configuration specified via\n   * [`defineConfig()`](#defineconfig).\n   * Common contractions and possessive nouns are split into 2 separate tokens;\n   * for example **I'll** splits as `'I'` and `'\\'ll'` or **won't** splits as\n   * `'wo'` and `'n\\'t'`.\n   *\n   * @method Tokenizer#tokenize\n   * @param {string} sentence the input sentence.\n   * @return {object[]} of tokens; each one of them is an object with 2-keys viz.\n   * `value` and its `tag` identifying the type of the token.\n   * @example\n   * var s = 'For detailed API docs, check out http://winkjs.org/wink-regression-tree/ URL!';\n   * myTokenizer.tokenize( s );\n   * // -> [ { value: 'For', tag: 'word' },\n   * //      { value: 'detailed', tag: 'word' },\n   * //      { value: 'API', tag: 'word' },\n   * //      { value: 'docs', tag: 'word' },\n   * //      { value: ',', tag: 'punctuation' },\n   * //      { value: 'check', tag: 'word' },\n   * //      { value: 'out', tag: 'word' },\n   * //      { value: 'http://winkjs.org/wink-regression-tree/', tag: 'url' },\n   * //      { value: 'URL', tag: 'word' },\n   * //      { value: '!', tag: 'punctuation' } ]\n  */\n  var tokenize = function ( sentence ) {\n    finalTokens = [];\n    tokenizeTextRecursively( sentence, rgxs );\n    return finalTokens;\n  }; // tokenize()\n\n  // ### getTokensFP\n  /**\n   *\n   * Returns the finger print of the tokens generated by the last call to\n   * [`tokenize()`](#tokenize). A finger print is a string created by sequentially\n   * joining the unique code of each token's type. Refer to table given under\n   * [`defineConfig()`](#defineconfig) for values of these codes.\n   *\n   * A finger print is extremely useful in spotting patterns present in the sentence\n   * using `regexes`, which is otherwise a complex and time consuming task.\n   *\n   * @method Tokenizer#getTokensFP\n   * @return {string} finger print of tokens generated by the last call to `tokenize()`.\n   * @example\n   * // Generate finger print of sentence given in the previous example\n   * // under tokenize().\n   * myTokenizer.getTokensFP();\n   * // -> 'wwww,wwuw!'\n  */\n  var getTokensFP = function () {\n    var fp = [];\n    finalTokens.forEach( function ( t ) {\n      fp.push( ( fingerPrintCodes[ t.tag ] ) ? fingerPrintCodes[ t.tag ] : t.value );\n    } );\n    return fp.join( '' );\n  }; // getFingerprint()\n\n  // ### addTag\n  var addTag = function (name, fingerprintCode) {\n    if (fingerPrintCodes[name]) {\n      throw new Error( 'Tag ' + name + ' already exists' );\n    }\n\n    fingerPrintCodes[name] = fingerprintCode;\n  }; // addTag()\n\n  // ### addRegex\n  /**\n   * Adds a regex for parsing a new type of token. This regex can either be mapped\n   * to an existing tag or it allows creation of a new tag along with its finger print.\n   * The uniqueness of the [finger prints](#defineconfig) have to ensured by the user.\n   *\n   * *The added regex(s) will supersede the internal parsing.*\n   *\n   * @method Tokenizer#addRegex\n   * @param {RegExp} regex the new regular expression.\n   * @param {string} tag tokens matching the `regex` will be assigned this tag.\n   * @param {string} [fingerprintCode=undefined] required if adding a new\n   * tag; ignored if using an existing tag.\n   * @return {void} nothing!\n   * @example\n   * // Adding a regex for an existing tag\n   * myTokenizer.addRegex( /\\(oo\\)/gi, 'emoticon' );\n   * myTokenizer.tokenize( '(oo) Hi!' )\n   * // -> [ { value: '(oo)', tag: 'emoticon' },\n   * //      { value: 'Hi', tag: 'word' },\n   * //      { value: '!', tag: 'punctuation' } ]\n   *\n   * // Adding a regex to parse a new token type\n   * myTokenizer.addRegex( /hello/gi, 'greeting', 'g' );\n   * myTokenizer.tokenize( 'hello, how are you?' );\n   * // -> [ { value: 'hello', tag: 'greeting' },\n   * //      { value: ',', tag: 'punctuation' },\n   * //      { value: 'how', tag: 'word' },\n   * //      { value: 'are', tag: 'word' },\n   * //      { value: 'you', tag: 'word' },\n   * //      { value: '?', tag: 'punctuation' } ]\n   * // Notice how \"hello\" is now tagged as \"greeting\" and not as \"word\".\n   *\n   * // Using definConfig will reset the above!\n   * myTokenizer.defineConfig( { word: true } );\n   * myTokenizer.tokenize( 'hello, how are you?' );\n   * // -> [ { value: 'hello', tag: 'word' },\n   * //      { value: ',', tag: 'punctuation' },\n   * //      { value: 'how', tag: 'word' },\n   * //      { value: 'are', tag: 'word' },\n   * //      { value: 'you', tag: 'word' },\n   * //      { value: '?', tag: 'punctuation' } ]\n  */\n\n  var addRegex = function (regex, tag, fingerprintCode) {\n    if (!fingerPrintCodes[tag] && !fingerprintCode) {\n      throw new Error( 'Tag ' + tag + ' doesn\\'t exist; Provide a \\'fingerprintCode\\' to add it as a tag.' );\n    } else if (!fingerPrintCodes[tag]) {\n      addTag(tag, fingerprintCode);\n    }\n\n    rgxs.unshift( { regex: regex, category: tag } );\n  }; // addRegex()\n\n  // Set quoted_phrase as false becuase mostly it is not required.\n  defineConfig( { quoted_phrase: false } ); // eslint-disable-line camelcase\n  methods.defineConfig = defineConfig;\n  methods.tokenize = tokenize;\n  methods.getTokensFP = getTokensFP;\n  methods.addTag = addTag;\n  methods.addRegex = addRegex;\n  return methods;\n};\n\nmodule.exports = tokenizer;\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA,IAAIA,UAAU,GAAGC,OAAO,CAAE,aAAF,CAAxB;;AACA,IAAIC,YAAY,GAAGD,OAAO,CAAE,uBAAF,CAA1B;;AACA,IAAIE,SAAS,GAAG,MAAhB,C,CACA;;AACA,IAAIC,YAAY,GAAG,mHAAnB,C,CACA;AACA;AACA;AACA;AACA;;AACA,IAAIC,WAAW,GAAG,wCAAlB,C,CACA;;AACA,IAAIC,WAAW,GAAG,yGAAlB;AACA,IAAIC,UAAU,GAAG,OAAjB,C,CACA;AACA;;AACA,IAAIC,YAAY,GAAG,mGAAnB,C,CACA;;AACA,IAAIC,YAAY,GAAG,gFAAnB,C,CACA;;AACA,IAAIC,QAAQ,GAAG,+GAAf,C,CACA;;AACA,IAAIC,WAAW,GAAG,cAAlB,C,CACA;;AACA,IAAIC,cAAc,GAAG,8CAArB;AACA,IAAIC,eAAe,GAAG,UAAtB,C,CACA;;AACA,IAAIC,MAAM,GAAG,2EAAb;AACA,IAAIC,QAAQ,GAAGf,UAAU,EAAzB;AACA,IAAIgB,WAAW,GAAG,wCAAlB;AACA,IAAIC,OAAO,GAAG,qEAAd,C,CACA;;AACA,IAAIC,SAAS,GAAG,8FAAhB,C,CACA;;AACA,IAAIC,SAAS,GAAG,8CAAhB,C,CACA;;AACA,IAAIC,SAAS,GAAG,6BAAhB,C,CACA;;AACA,IAAIC,cAAc,GAAG,GAArB,C,CACA;;AACA,IAAIC,cAAc,GAAG,gBAArB;AACA,IAAIC,YAAY,GAAG,gBAAnB,C,CACA;AACA;;AACA,IAAIC,UAAU,GAAG,CACf;EAAEC,KAAK,EAAEZ,eAAT;EAA0Ba,QAAQ,EAAE;AAApC,CADe,EAEf;EAAED,KAAK,EAAEX,MAAT;EAAiBY,QAAQ,EAAE;AAA3B,CAFe,EAGf;EAAED,KAAK,EAAEf,QAAT;EAAmBgB,QAAQ,EAAE;AAA7B,CAHe,EAIf;EAAED,KAAK,EAAElB,UAAT;EAAqBmB,QAAQ,EAAE;AAA/B,CAJe,EAKf;EAAED,KAAK,EAAEjB,YAAT;EAAuBkB,QAAQ,EAAE;AAAjC,CALe,EAMf;EAAED,KAAK,EAAEhB,YAAT;EAAuBiB,QAAQ,EAAE;AAAjC,CANe,EAOf;EAAED,KAAK,EAAEV,QAAT;EAAmBW,QAAQ,EAAE;AAA7B,CAPe,EAQf;EAAED,KAAK,EAAET,WAAT;EAAsBU,QAAQ,EAAE;AAAhC,CARe,EASf;EAAED,KAAK,EAAER,OAAT;EAAkBS,QAAQ,EAAE;AAA5B,CATe,EAUf;EAAED,KAAK,EAAErB,YAAT;EAAuBsB,QAAQ,EAAE;AAAjC,CAVe,EAWf;EAAED,KAAK,EAAEpB,WAAT;EAAsBqB,QAAQ,EAAE;AAAhC,CAXe,EAYf;EAAED,KAAK,EAAEnB,WAAT;EAAsBoB,QAAQ,EAAE;AAAhC,CAZe,EAaf;EAAED,KAAK,EAAEd,WAAT;EAAsBe,QAAQ,EAAE;AAAhC,CAbe,EAcf;EAAED,KAAK,EAAEP,SAAT;EAAoBQ,QAAQ,EAAE;AAA9B,CAde,EAef;EAAED,KAAK,EAAEN,SAAT;EAAoBO,QAAQ,EAAE;AAA9B,CAfe,EAgBf;EAAED,KAAK,EAAEb,cAAT;EAAyBc,QAAQ,EAAE;AAAnC,CAhBe,EAiBf;EAAED,KAAK,EAAEL,SAAT;EAAoBM,QAAQ,EAAE;AAA9B,CAjBe,CAAjB,C,CAoBA;AACA;;AACA,IAAIC,gBAAgB,GAAG;EACrBC,QAAQ,EAAE,GADW;EAErBC,KAAK,EAAE,GAFc;EAGrBC,KAAK,EAAE,GAHc;EAIrBC,OAAO,EAAE,GAJY;EAKrBC,OAAO,EAAE,GALY;EAMrBC,MAAM,EAAE,GANa;EAOrBC,OAAO,EAAE,GAPY;EAQrBC,aAAa,EAAE,GARM;EAQD;EACpBC,QAAQ,EAAE,GATW;EAUrB;EACAC,IAAI,EAAE,GAXe;EAYrBC,GAAG,EAAE,GAZgB;EAarBC,IAAI,EAAE,GAbe;EAcrBC,KAAK,EAAE;AAdc,CAAvB,C,CAiBA;;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,IAAIC,SAAS,GAAG,YAAY;EAC1B;EACA,IAAIC,IAAI,GAAGlB,UAAU,CAACmB,KAAX,CAAkB,CAAlB,CAAX,CAF0B,CAG1B;;EACA,IAAIC,WAAW,GAAG,EAAlB,CAJ0B,CAK1B;;EAEA;AACF;AACA;AACA;AACA;;EACE,IAAIC,OAAO,GAAGC,MAAM,CAACC,MAAP,CAAe,IAAf,CAAd,CAZ0B,CAc1B;;EACA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;EACE,IAAIC,iBAAiB,GAAG,UAAWT,IAAX,EAAiBU,MAAjB,EAA0B;IAChD,IAAIC,EAAE,GAAGhD,YAAY,CAAEqC,IAAF,CAArB;IACA,IAAIY,OAAJ;;IACA,IAAKD,EAAE,KAAKE,SAAZ,EAAwB;MACtB;MACAD,OAAO,GAAGZ,IAAI,CAACc,KAAL,CAAY/B,cAAZ,CAAV;;MACA,IAAK6B,OAAL,EAAe;QACbF,MAAM,CAACK,IAAP,CAAa;UAAEC,KAAK,EAAEJ,OAAO,CAAE,CAAF,CAAhB;UAAuBK,GAAG,EAAE;QAA5B,CAAb;QACAP,MAAM,CAACK,IAAP,CAAa;UAAEC,KAAK,EAAEJ,OAAO,CAAE,CAAF,CAAhB;UAAuBK,GAAG,EAAE;QAA5B,CAAb;MACD,CAHD,MAGO;QACLL,OAAO,GAAGZ,IAAI,CAACc,KAAL,CAAY9B,YAAZ,CAAV;;QACA,IAAK4B,OAAL,EAAe;UACbF,MAAM,CAACK,IAAP,CAAa;YAAEC,KAAK,EAAEJ,OAAO,CAAE,CAAF,CAAhB;YAAuBK,GAAG,EAAE;UAA5B,CAAb;UACAP,MAAM,CAACK,IAAP,CAAa;YAAEC,KAAK,EAAEJ,OAAO,CAAE,CAAF,CAAhB;YAAuBK,GAAG,EAAE;UAA5B,CAAb;QACD,CAHD,MAGOP,MAAM,CAACK,IAAP,CAAa;UAAEC,KAAK,EAAEhB,IAAT;UAAeiB,GAAG,EAAE;QAApB,CAAb;MACR;IACF,CAbD,MAaO;MACL;MACAP,MAAM,CAACK,IAAP,CAAaR,MAAM,CAACW,MAAP,CAAe,EAAf,EAAmBP,EAAE,CAAE,CAAF,CAArB,CAAb;MACAD,MAAM,CAACK,IAAP,CAAaR,MAAM,CAACW,MAAP,CAAe,EAAf,EAAmBP,EAAE,CAAE,CAAF,CAArB,CAAb;MACA,IAAKA,EAAE,CAAE,CAAF,CAAP,EAAeD,MAAM,CAACK,IAAP,CAAaR,MAAM,CAACW,MAAP,CAAe,EAAf,EAAmBP,EAAE,CAAE,CAAF,CAArB,CAAb;IAChB;;IACD,OAAOD,MAAP;EACD,CAvBD,CA3B0B,CAkDvB;EAEH;;EACA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;EACE,IAAIS,gBAAgB,GAAG,UAAWC,IAAX,EAAiBC,QAAjB,EAA4B;IACjD;IACA;IACA,IAAIT,OAAO,GAAGQ,IAAI,CAACN,KAAL,CAAYO,QAAQ,CAACnC,KAArB,CAAd,CAHiD,CAIjD;;IACA,IAAIoC,OAAO,GAAGF,IAAI,CAACG,KAAL,CAAYF,QAAQ,CAACnC,KAArB,CAAd,CALiD,CAMjD;;IACA,IAAIwB,MAAM,GAAG,EAAb,CAPiD,CAQjD;;IACA,IAAIO,GAAG,GAAGI,QAAQ,CAAClC,QAAnB,CATiD,CAUjD;;IACA,IAAIqC,KAAJ;IAAA,IACIC,CADJ;IAAA,IAEIC,IAFJ;IAAA,IAGIC,CAAC,GAAG,CAHR;IAAA,IAIIC,CAJJ,CAXiD,CAiBjD;;IACAhB,OAAO,GAAKA,OAAF,GAAcA,OAAd,GAAwB,EAAlC;;IACA,KAAMa,CAAC,GAAG,CAAJ,EAAOC,IAAI,GAAGJ,OAAO,CAACO,MAA5B,EAAoCJ,CAAC,GAAGC,IAAxC,EAA8CD,CAAC,IAAI,CAAnD,EAAuD;MACrDG,CAAC,GAAGN,OAAO,CAAEG,CAAF,CAAX;MACAG,CAAC,GAAGA,CAAC,CAACE,IAAF,EAAJ;MACA,IAAKF,CAAL,EAASlB,MAAM,CAACK,IAAP,CAAaa,CAAb;;MACT,IAAKD,CAAC,GAAGf,OAAO,CAACiB,MAAjB,EAA0B;QACxB,IAAKZ,GAAG,KAAK,MAAb,EAAsB;UACpB;UACAO,KAAK,GAAGZ,OAAO,CAAEe,CAAF,CAAf;;UACA,IAAK7C,cAAc,CAACiD,IAAf,CAAqBP,KAArB,CAAL,EAAoC;YAClCd,MAAM,GAAGD,iBAAiB,CAAEe,KAAF,EAASd,MAAT,CAA1B;UACD,CAFD,MAEO;YACL;YACAA,MAAM,CAACK,IAAP,CAAa;cAAEC,KAAK,EAAEQ,KAAT;cAAgBP,GAAG,EAAEA;YAArB,CAAb;UACD;QACF,CATD,MASOP,MAAM,CAACK,IAAP,CAAa;UAAEC,KAAK,EAAEJ,OAAO,CAAEe,CAAF,CAAhB;UAAuBV,GAAG,EAAEA;QAA5B,CAAb;MACR;;MACDU,CAAC,IAAI,CAAL;IACD;;IAED,OAASjB,MAAT;EACD,CAvCD,CAlE0B,CAyGvB;EAEH;;EACA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;EACE,IAAIsB,uBAAuB,GAAG,UAAWZ,IAAX,EAAiBa,OAAjB,EAA2B;IACvD,IAAIC,QAAQ,GAAGd,IAAI,CAACU,IAAL,EAAf;IACA,IAAIpB,MAAM,GAAG,EAAb;IACA,IAAIe,CAAJ,EAAOC,IAAP;;IAEA,IAAK,CAACO,OAAO,CAACJ,MAAd,EAAuB;MACrB;MACAT,IAAI,CAACG,KAAL,CAAY3D,SAAZ,EAAwBuE,OAAxB,CAAiC,UAAWC,GAAX,EAAiB;QAChD/B,WAAW,CAACU,IAAZ,CAAkB;UAAEC,KAAK,EAAEoB,GAAG,CAACN,IAAJ,EAAT;UAAqBb,GAAG,EAAE;QAA1B,CAAlB;MACD,CAFD;MAGA;IACD;;IAED,IAAIoB,GAAG,GAAGJ,OAAO,CAAE,CAAF,CAAjB;IACAvB,MAAM,GAAGS,gBAAgB,CAAEe,QAAF,EAAYG,GAAZ,CAAzB;;IAEA,KAAMZ,CAAC,GAAG,CAAJ,EAAOC,IAAI,GAAGhB,MAAM,CAACmB,MAA3B,EAAmCJ,CAAC,GAAGC,IAAvC,EAA6CD,CAAC,IAAI,CAAlD,EAAsD;MACpD,IAAK,OAAOf,MAAM,CAAEe,CAAF,CAAb,KAAuB,QAA5B,EAAuC;QACrC;QACAO,uBAAuB,CAAEtB,MAAM,CAAEe,CAAF,CAAR,EAAeQ,OAAO,CAAC7B,KAAR,CAAe,CAAf,CAAf,CAAvB;MACD,CAHD,MAGO;QACLC,WAAW,CAACU,IAAZ,CAAkBL,MAAM,CAAEe,CAAF,CAAxB;MACD;IACF;EACF,CAxBD,CAxH0B,CAgJvB;EAEH;;EACA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;EACE,IAAIa,YAAY,GAAG,UAAWC,MAAX,EAAoB;IACrC,IAAK,OAAOA,MAAP,KAAkB,QAAlB,IAA8BhC,MAAM,CAACiC,IAAP,CAAaD,MAAb,EAAsBV,MAAzD,EAAkE;MAChE1B,IAAI,GAAGlB,UAAU,CAACwD,MAAX,CAAmB,UAAWJ,GAAX,EAAiB;QACzC;QACA,IAAIK,EAAE,GAAGH,MAAM,CAAEF,GAAG,CAAClD,QAAN,CAAf,CAFyC,CAGzC;QACA;;QACA,OAASuD,EAAE,KAAK7B,SAAP,IAAoB6B,EAAE,KAAK,IAA3B,IAAmC,CAAC,CAACA,EAA9C;MACD,CANM,CAAP;IAOD,CARD,MAQOvC,IAAI,GAAG,EAAP,CAT8B,CAUrC;;;IACA,MAAMwC,UAAU,GAAGpC,MAAM,CAACC,MAAP,CAAe,IAAf,CAAnB;IACAL,IAAI,CAACgC,OAAL,CAAc,UAAWE,GAAX,EAAiB;MAC7BM,UAAU,CAAEN,GAAG,CAAClD,QAAN,CAAV,GAA6B,IAA7B;IACD,CAFD,EAZqC,CAerC;;IACAC,gBAAgB,GAAG;MACjBC,QAAQ,EAAE,GADO;MAEjBC,KAAK,EAAE,GAFU;MAGjBC,KAAK,EAAE,GAHU;MAIjBC,OAAO,EAAE,GAJQ;MAKjBC,OAAO,EAAE,GALQ;MAMjBC,MAAM,EAAE,GANS;MAOjBC,OAAO,EAAE,GAPQ;MAQjBC,aAAa,EAAE,GARE;MAQG;MACpBC,QAAQ,EAAE,GATO;MAUjB;MACAC,IAAI,EAAE,GAXW;MAYjBC,GAAG,EAAE,GAZY;MAajBC,IAAI,EAAE,GAbW;MAcjBC,KAAK,EAAE;IAdU,CAAnB;IAgBA,OAAWM,MAAM,CAACiC,IAAP,CAAaG,UAAb,CAAF,CAA8Bd,MAAvC;EACD,CAjCD,CAhM0B,CAiOvB;EAEH;;EACA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;EACE,IAAIe,QAAQ,GAAG,UAAWV,QAAX,EAAsB;IACnC7B,WAAW,GAAG,EAAd;IACA2B,uBAAuB,CAAEE,QAAF,EAAY/B,IAAZ,CAAvB;IACA,OAAOE,WAAP;EACD,CAJD,CA9P0B,CAkQvB;EAEH;;EACA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;EACE,IAAIwC,WAAW,GAAG,YAAY;IAC5B,IAAIC,EAAE,GAAG,EAAT;IACAzC,WAAW,CAAC8B,OAAZ,CAAqB,UAAWP,CAAX,EAAe;MAClCkB,EAAE,CAAC/B,IAAH,CAAW3B,gBAAgB,CAAEwC,CAAC,CAACX,GAAJ,CAAlB,GAAgC7B,gBAAgB,CAAEwC,CAAC,CAACX,GAAJ,CAAhD,GAA4DW,CAAC,CAACZ,KAAvE;IACD,CAFD;IAGA,OAAO8B,EAAE,CAACC,IAAH,CAAS,EAAT,CAAP;EACD,CAND,CAvR0B,CA6RvB;EAEH;;;EACA,IAAIC,MAAM,GAAG,UAAUC,IAAV,EAAgBC,eAAhB,EAAiC;IAC5C,IAAI9D,gBAAgB,CAAC6D,IAAD,CAApB,EAA4B;MAC1B,MAAM,IAAIE,KAAJ,CAAW,SAASF,IAAT,GAAgB,iBAA3B,CAAN;IACD;;IAED7D,gBAAgB,CAAC6D,IAAD,CAAhB,GAAyBC,eAAzB;EACD,CAND,CAhS0B,CAsSvB;EAEH;;EACA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;EAEE,IAAIE,QAAQ,GAAG,UAAUlE,KAAV,EAAiB+B,GAAjB,EAAsBiC,eAAtB,EAAuC;IACpD,IAAI,CAAC9D,gBAAgB,CAAC6B,GAAD,CAAjB,IAA0B,CAACiC,eAA/B,EAAgD;MAC9C,MAAM,IAAIC,KAAJ,CAAW,SAASlC,GAAT,GAAe,oEAA1B,CAAN;IACD,CAFD,MAEO,IAAI,CAAC7B,gBAAgB,CAAC6B,GAAD,CAArB,EAA4B;MACjC+B,MAAM,CAAC/B,GAAD,EAAMiC,eAAN,CAAN;IACD;;IAED/C,IAAI,CAACkD,OAAL,CAAc;MAAEnE,KAAK,EAAEA,KAAT;MAAgBC,QAAQ,EAAE8B;IAA1B,CAAd;EACD,CARD,CApV0B,CA4VvB;EAEH;;;EACAqB,YAAY,CAAE;IAAE1C,aAAa,EAAE;EAAjB,CAAF,CAAZ,CA/V0B,CA+VgB;;EAC1CU,OAAO,CAACgC,YAAR,GAAuBA,YAAvB;EACAhC,OAAO,CAACsC,QAAR,GAAmBA,QAAnB;EACAtC,OAAO,CAACuC,WAAR,GAAsBA,WAAtB;EACAvC,OAAO,CAAC0C,MAAR,GAAiBA,MAAjB;EACA1C,OAAO,CAAC8C,QAAR,GAAmBA,QAAnB;EACA,OAAO9C,OAAP;AACD,CAtWD;;AAwWAgD,MAAM,CAACC,OAAP,GAAiBrD,SAAjB"},"metadata":{},"sourceType":"script"}